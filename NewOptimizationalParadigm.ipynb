{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys, os\n",
    "\n",
    "from sys import platform\n",
    "from decimal import *\n",
    "\n",
    "\n",
    "path='./'\n",
    "if platform == 'win32' :\n",
    "    #path ='/workspace'\n",
    "    path ='C:/Users/Sergey/Desktop/Natixis/Yeti'\n",
    "\n",
    "\n",
    "import keras, tensorflow, pkg_resources\n",
    "dataDirectory = 'Data'\n",
    "dataLearningFile = \"1dim_VolLoc-Example-new.CSV\"\n",
    "dataNotationFile = \"1dim_VolLoc-Example-new.CSV\"\n",
    "\n",
    "os.chdir(path)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from math import sqrt, exp, log, erf,floor\n",
    "import numpy \n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "from keras import callbacks\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "import keras.layers\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as pyplot\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import mpl_toolkits\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from IPython.display import display\n",
    "import time\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual,FloatProgress\n",
    "import ipywidgets as widgets\n",
    "import math\n",
    "import threading\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "# Generate dummy data\n",
    "\n",
    "\n",
    "\n",
    "getcontext().prec = 8\n",
    "from util_functions_YetiPhen_VolLoc import *\n",
    "\n",
    "import pkg_resources\n",
    "\n",
    "ListField1 ={\"S1\", \"mu1\", \"bonus\", \"YetiBarrier\", \"YetiCoupon\", \"PhoenixBarrier\",\"PhoenixCoupon\",\"PDIBarrier\",\"PDIGearing\",\"PDIStrike\",\"PDIType\",\n",
    "             \"maturity\",\"nbDates\"}\n",
    "\n",
    "ListField2={\"vol-date0-strike0\",\"vol-date0-strike1\",\"vol-date0-strike2\",\"vol-date0-strike3\",\"vol-date0-strike4\",\"vol-date0-strike5\",\"vol-date0-strike6\",\n",
    "           \"vol-date0-strike7\",\"vol-date0-strike8\",\"vol-date0-strike9\",\"vol-date0-strike10\",\"vol-date0-strike11\",\"vol-date0-strike12\",\"vol-date0-strike13\",\n",
    "           \"vol-date0-strike14\",\"vol-date1-strike0\",\"vol-date1-strike1\",\"vol-date1-strike2\",\"vol-date1-strike3\",\"vol-date1-strike4\",\"vol-date1-strike5\",\n",
    "           \"vol-date1-strike6\",\"vol-date1-strike7\",\"vol-date1-strike8\",\"vol-date1-strike9\",\"vol-date1-strike10\",\"vol-date1-strike11\",\"vol-date1-strike12\",\n",
    "           \"vol-date1-strike13\",\"vol-date1-strike14\",\"vol-date2-strike0\",\"vol-date2-strike1\",\"vol-date2-strike2\",\"vol-date2-strike3\",\"vol-date2-strike4\",\n",
    "           \"vol-date2-strike5\",\"vol-date2-strike6\",\"vol-date2-strike7\",\"vol-date2-strike8\",\"vol-date2-strike9\",\"vol-date2-strike10\",\"vol-date2-strike11\",\n",
    "           \"vol-date2-strike12\",\"vol-date2-strike13\",\"vol-date2-strike14\",\"vol-date3-strike0\",\"vol-date3-strike1\",\"vol-date3-strike2\",\"vol-date3-strike3\",\n",
    "           \"vol-date3-strike4\",\"vol-date3-strike5\",\"vol-date3-strike6\",\"vol-date3-strike7\",\"vol-date3-strike8\",\"vol-date3-strike9\",\"vol-date3-strike10\",\n",
    "           \"vol-date3-strike11\",\"vol-date3-strike12\",\"vol-date3-strike13\",\"vol-date3-strike14\",\"vol-date4-strike0\",\"vol-date4-strike1\",\"vol-date4-strike2\",\n",
    "           \"vol-date4-strike3\",\"vol-date4-strike4\",\"vol-date4-strike5\",\"vol-date4-strike6\",\"vol-date4-strike7\",\"vol-date4-strike8\",\"vol-date4-strike9\",\n",
    "           \"vol-date4-strike10\",\"vol-date4-strike11\",\"vol-date4-strike12\",\"vol-date4-strike13\",\"vol-date4-strike14\",\"vol-date5-strike0\",\"vol-date5-strike1\",\n",
    "           \"vol-date5-strike2\",\"vol-date5-strike3\",\"vol-date5-strike4\",\"vol-date5-strike5\",\"vol-date5-strike6\",\"vol-date5-strike7\",\"vol-date5-strike8\",\n",
    "           \"vol-date5-strike9\",\"vol-date5-strike10\",\"vol-date5-strike11\",\"vol-date5-strike12\",\"vol-date5-strike13\",\"vol-date5-strike14\",\"vol-date6-strike0\",\n",
    "           \"vol-date6-strike1\",\"vol-date6-strike2\",\"vol-date6-strike3\",\"vol-date6-strike4\",\"vol-date6-strike5\",\"vol-date6-strike6\",\"vol-date6-strike7\",\n",
    "           \"vol-date6-strike8\",\"vol-date6-strike9\",\"vol-date6-strike10\",\"vol-date6-strike11\",\"vol-date6-strike12\",\"vol-date6-strike13\",\"vol-date6-strike14\",\n",
    "           \"vol-date7-strike0\",\"vol-date7-strike1\",\"vol-date7-strike2\",\"vol-date7-strike3\",\"vol-date7-strike4\",\"vol-date7-strike5\",\"vol-date7-strike6\",\n",
    "           \"vol-date7-strike7\",\"vol-date7-strike8\",\"vol-date7-strike9\",\"vol-date7-strike10\",\"vol-date7-strike11\",\"vol-date7-strike12\",\"vol-date7-strike13\",\n",
    "           \"vol-date7-strike14\",\"vol-date8-strike0\",\"vol-date8-strike1\",\"vol-date8-strike2\",\"vol-date8-strike3\",\"vol-date8-strike4\",\"vol-date8-strike5\",\n",
    "           \"vol-date8-strike6\",\"vol-date8-strike7\",\"vol-date8-strike8\",\"vol-date8-strike9\",\"vol-date8-strike10\",\"vol-date8-strike11\",\"vol-date8-strike12\",\n",
    "           \"vol-date8-strike13\",\"vol-date8-strike14\",\"vol-date9-strike0\",\"vol-date9-strike1\",\"vol-date9-strike2\",\"vol-date9-strike3\",\"vol-date9-strike4\",\n",
    "           \"vol-date9-strike5\",\"vol-date9-strike6\",\"vol-date9-strike7\",\"vol-date9-strike8\",\"vol-date9-strike9\",\"vol-date9-strike10\",\"vol-date9-strike11\",\n",
    "           \"vol-date9-strike12\",\"vol-date9-strike13\",\"vol-date9-strike14\",\"vol-date10-strike0\",\"vol-date10-strike1\",\"vol-date10-strike2\",\"vol-date10-strike3\",\n",
    "           \"vol-date10-strike4\",\"vol-date10-strike5\",\"vol-date10-strike6\",\"vol-date10-strike7\",\"vol-date10-strike8\",\"vol-date10-strike9\",\"vol-date10-strike10\",\n",
    "           \"vol-date10-strike11\",\"vol-date10-strike12\",\"vol-date10-strike13\",\"vol-date10-strike14\",\"vol-date11-strike0\",\"vol-date11-strike1\",\"vol-date11-strike2\",\n",
    "           \"vol-date11-strike3\",\"vol-date11-strike4\",\"vol-date11-strike5\",\"vol-date11-strike6\",\"vol-date11-strike7\",\n",
    "           \"vol-date11-strike8\",\"vol-date11-strike9\",\"vol-date11-strike10\",\"vol-date11-strike11\",\"vol-date11-strike12\",\"vol-date11-strike13\",\"vol-date11-strike14\"}\n",
    "\n",
    "dataDirectory = 'Data'\n",
    "dataLearningFile = \"1dim_VolLoc-Example-new.CSV\"\n",
    "dataNotationFile = \"1dim_VolLoc-Example-new.CSV\"\n",
    "\n",
    "params = metaparameters()\n",
    "\n",
    "params.INPUT_DIM  = 193\n",
    "params.INPUT_OPTION = 193\n",
    "params.INPUT_VOL = 13\n",
    "params.NB_NEURON_PRINCIPAL = 8\n",
    "params.ACTIVATION_PRINCIPALE = 'tanh'\n",
    "params.ACTIVATION_PRINCIPALE_FINALE = 'linear'\n",
    "params.INITIAL_LEARNING_NB_EPOCH = 1000\n",
    "params.LEARNINGBASE_ORIGIN = \"New_Test\"\n",
    "params.LEARNINGBASE_BUT = \"New_Simu_Test\"\n",
    "params.GENETIC_LEARNING_NB_EPOCH = 10\n",
    "params.BATCH_SIZE_PRINCIPAL = 32768\n",
    "params.OPTIMIZER = 'adamax'##############################\n",
    "params.OPTIMIZER_GENETIC = 'SGD'###########################\n",
    "params.NBLAYERS = 11\n",
    "params.NB_LOOPS = 5\n",
    "params.PATH = path\n",
    "params.VERBOSE_FLAG = 2\n",
    "params.EPSILON_GREEDINESS = 0.25\n",
    "params.EPSILON_GREEDINESS_DECREASING_FACTOR = 0.99\n",
    "params.INITIAL_NETWORK_STRUCTURE = [[0,10], [1,20], [2,30], [0,10]]\n",
    "params.NOTATION_FILE = dataDirectory + '/' + dataNotationFile\n",
    "params.LISTFIELD1 = ListField1\n",
    "params.LISTFIELD2 = ListField2\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temps de lecture du ficher 0.06297445297241211\n",
      "temps de lecture du ficher 0.06196141242980957\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "dataframe = pandas.read_csv(dataDirectory + \"/\" + dataLearningFile)\n",
    "endTime = time.time()\n",
    "print('temps de lecture du ficher', endTime - startTime)\n",
    "X = dataframe.loc[:, ListField1.union(ListField2)];\n",
    "Y_Vol = dataframe['price'];\n",
    "datasize = X.size\n",
    "X_scaler = preprocessing.MinMaxScaler(feature_range = (0, 1))\n",
    "X_scaled = (X_scaler.fit_transform(X))\n",
    "\n",
    "params.X_scaler = X_scaler\n",
    "params.X_scaled = X_scaled\n",
    "params.X = X\n",
    "Y_scaler = preprocessing.MinMaxScaler(feature_range = (0, 1))\n",
    "Y_scaled = (Y_scaler.fit_transform(np.array(Y_Vol).reshape(-1, 1))).reshape(1, -1)[0]\n",
    "params.Y_scaler = Y_scaler\n",
    "params.Y_scaled = Y_scaled\n",
    "params.Y_Vol = Y_Vol\n",
    "\n",
    "startTime = time.time()\n",
    "dataframe = pandas.read_csv(dataDirectory + \"/\" + dataNotationFile)\n",
    "endTime = time.time()\n",
    "print('temps de lecture du ficher', endTime - startTime)\n",
    "X = dataframe.loc[:, ListField1.union(ListField2)];\n",
    "Y_Vol = dataframe['price'];\n",
    "datasize = X.size\n",
    "X_scaler = preprocessing.MinMaxScaler(feature_range = (0, 1))\n",
    "X_scaled = (X_scaler.fit_transform(X))\n",
    "params.X_Notation_scaler = X_scaler\n",
    "params.X_Notation_scaled = X_scaled\n",
    "params.X_Notation = X\n",
    "Y_scaler = preprocessing.MinMaxScaler(feature_range = (0, 1))\n",
    "Y_scaled = (Y_scaler.fit_transform(np.array(Y_Vol).reshape(-1, 1))).reshape(1, -1)[0]\n",
    "params.Y_Notation_scaler = Y_scaler\n",
    "params.Y_Notation_scaled = Y_scaled\n",
    "params.Y_Notation_Vol = Y_Vol\n",
    "\n",
    "\n",
    "\n",
    "params.N_MODELS_LIMIT_SIMULTANEOUSLY = 16\n",
    "params.RANGE = [4,8,16]#range(N_MODELS_SIM, N_MODELS_SIM + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator_N(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_FICHIERS, n_dims = 16, size_FICHIERS = 10000, batch_size = 20, shuffle=True, mode = 'train'):\n",
    "        'Initialization'\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.list_FICHIERS = list_FICHIERS\n",
    "        \n",
    "        self.n_fichiers = len(self.list_FICHIERS)\n",
    "        \n",
    "        self.size_fichiers = size_FICHIERS\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "               \n",
    "        self.n_dims = n_dims\n",
    "        \n",
    "        assert(mode in {'train', 'val', 'test'})\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.current_fichier = 0\n",
    "        # '256Ks/'+ str(self.list_FICHIERS[self.current_fichier]) +'.csv'\n",
    "        self.data = pd.read_csv(self.list_FICHIERS[self.current_fichier], sep = ';')\n",
    "        \n",
    "        self.batches_per_fichier = size_FICHIERS // batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(self.n_fichiers * self.size_fichiers / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index): \n",
    "        \n",
    "        if index // self.batches_per_fichier != self.current_fichier:\n",
    "            self.current_fichier = index // self.batches_per_fichier\n",
    "            \n",
    "            # '256Ks/'+ str(self.list_FICHIERS[self.current_fichier]) +'.csv'\n",
    "            self.data = pd.read_csv(self.list_FICHIERS[self.current_fichier], sep = ';')\n",
    "            self.data = self.data.reset_index(drop = 'index')\n",
    "        \n",
    "        intra_index = index % self.batches_per_fichier\n",
    "\n",
    "        data_temp = self.data.loc[intra_index * self.batch_size : (intra_index + 1) * self.batch_size - 1]\n",
    "        \n",
    "        Y = data_temp.price.values\n",
    "        X = data_temp.drop(columns = ['nbDates', 'price']).values\n",
    "\n",
    "        \n",
    "        if self.mode in {'train', 'val'}:\n",
    "            Y = Y.reshape((-1, 1))\n",
    "            Y = np.squeeze(np.repeat(Y[:, np.newaxis, :], self.n_dims, axis = 1))\n",
    "        else:\n",
    "            Y = [Y for i in range(self.n_dims)]\n",
    "        return X, Y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.list_FICHIERS)\n",
    "\n",
    "        self.current_fichier = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_to = '/workspace/FirstAttempt/Data/Sergey/'\n",
    "path_to = 'C:/Users/Sergey/Desktop/Natixis/DataSamples/'\n",
    "list_gen = [path_to + str(i) + '.csv' for i in range(5)]\n",
    "\n",
    "\n",
    "TRAIN_GENs = {i : DataGenerator_N(list_gen[:3], n_dims = i, mode = 'train') for i in params.RANGE}\n",
    "VAL_GENs = {i : DataGenerator_N([list_gen[3]], n_dims = i, mode = 'val') for i in params.RANGE}\n",
    "TEST_GENs = {i : DataGenerator_N([list_gen[4]], n_dims = i, mode = 'test') for i in params.RANGE}\n",
    "\n",
    "#dg = DataGenerator_N(list_gen[:3], n_dims = 10, mode = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildParamList(modelspecList, params):\n",
    "    \n",
    "    model = buidModel(modelspecList, params)   \n",
    "    weights1 = model.get_weights()\n",
    "    \n",
    "    return list(map(lambda k: k.shape, weights1))\n",
    "\n",
    "def CountIndividuals(a):\n",
    "    \n",
    "    ii = 0\n",
    "    for f in os.listdir(a):\n",
    "        ii = ii + 1\n",
    "        \n",
    "    return ii\n",
    "\n",
    "def convergeIndividualModel(model2):\n",
    "    \n",
    "    print('convergeIndividualModel :')\n",
    "    \n",
    "    return None\n",
    "   \n",
    "\n",
    "def pathCreatechild(TimePath, individualpath, child):\n",
    "    \n",
    "    pathCreated = TimePath + '/individu' +  str(child)\n",
    "    \n",
    "    if not(os.path.isdir(pathCreated)):\n",
    "        os.makedirs(pathCreated, 0o777)\n",
    "        \n",
    "    print('pathCreatechild=', pathCreated)\n",
    "    \n",
    "    return pathCreated\n",
    "\n",
    "def killIndividual(individualPath):\n",
    "    \n",
    "    print(\"killing :\", individualPath)\n",
    "    shutil.rmtree(individualPath)\n",
    "    \n",
    "def saveIndividualModel(model, specList, path, cnfigName):\n",
    "    \n",
    "    model.save_weights(path + '/' + cnfigName + '.hdf5')\n",
    "\n",
    "    model_json = model.to_json()\n",
    "    \n",
    "    with open(path + '/' + cnfigName +'.json', 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "    filename = path + '/' + cnfigName + 'current_structure.str'\n",
    "    _= joblib.dump(specList, filename, compress = 9)\n",
    "    \n",
    "    print('saveIndividualModel model2 at :', path)\n",
    "\n",
    "    \n",
    "def loadInvidualModel(IndividuPath, cnfigName):\n",
    "    \n",
    "    json_file = open(IndividuPath + \"/\" + cnfigName  + '.json', 'r')\n",
    "    file = IndividuPath + '/' + cnfigName  + '.json'\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()  \n",
    "    \n",
    "    loaded_model = model_from_json(loaded_model_json)  \n",
    "    \n",
    "    filename2 = IndividuPath + '/' + cnfigName  + 'current_structure.str'\n",
    "    specList = joblib.load(filename2)\n",
    "    \n",
    "    print('loadInvidualModel :IndividuPath=', IndividuPath)\n",
    "    \n",
    "    return loaded_model, specList\n",
    "\n",
    "def mutateIndividualModel(model, speclist):\n",
    "    \n",
    "    model1 = injectionModel(model, speclist, deltaspecList, params) \n",
    "    print('mutateIndividualModel :')\n",
    "    \n",
    "    return model1, speclist\n",
    "\n",
    "def copyModelFromInitial(originalModelPath, IndividuPath):\n",
    "    \n",
    "    shutil.copyfile(originalModelPath + 'current_structure.str', IndividuPath + 'current_structure.str')\n",
    " \n",
    "    \n",
    "\n",
    "def Idealpopulation(nstep):\n",
    "    \n",
    "    if (nstep < 4): \n",
    "        return 3 * nstep + 2\n",
    "    else:\n",
    "        return 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def injectionModel(model, modelspecList, deltaspecList, params): \n",
    "    \n",
    "    modelspeclist2 = [[modelspecList[i][0], modelspecList[i][1] + deltaspecList[i]] for i in range(len(modelspecList))]\n",
    "    model2 = buidModel(modelspeclist2, params)\n",
    "    \n",
    "    ## debut de la recopie des poids\n",
    "    weights1 = model.get_weights()\n",
    "    param_list = list(map(lambda k: k.shape, weights1))\n",
    "    weights2 = model2.get_weights()\n",
    "    \n",
    "  ## debut de la recopie des poids\n",
    "    for iparam in range(len(param_list)):\n",
    "        w = subcopy(weights1[iparam], weights2[iparam], param_list[iparam])\n",
    "        weights2[iparam] = w  \n",
    "    ########################################################################\n",
    "    ########################################################################\n",
    "    ########################################################################\n",
    "    #G = 4\n",
    "    #model2 = keras.utils.multi_gpu_model(model2, gpus = G)\n",
    "    #model2.compile(loss = 'mse', optimizer = optimizer, metrics = [\"mse\"])\n",
    "    model2.set_weights(weights2) \n",
    "    \n",
    "    return model2\n",
    "\n",
    "def mutateIndividualModel(model, specList, params):\n",
    "    \n",
    "    NbLayers = len(specList)\n",
    "    deltaNbNeuronList = BulleListPar(0, NbLayers)\n",
    "    \n",
    "    print('mutateIndividualModel : adding neurons', deltaNbNeuronList)\n",
    "    print('specList=', specList)\n",
    "    print('deltaNbNeuronList=', deltaNbNeuronList)\n",
    "    \n",
    "    model2 = injectionModel(model, specList, deltaNbNeuronList, params) \n",
    "    specList2 = [[specList[i][0], specList[i][1] + deltaNbNeuronList[i]] for i in range(NbLayers)]\n",
    "    \n",
    "    return model2, specList2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OP = {'lr':0.001, 'momentum':0.01, 'decay':0.99, 'nesterov':False}\n",
    "# opt = Optimizer('SGD', OP)\n",
    "\n",
    "# joblib.dump(opt, 'C:/Users/Sergey/Desktop/Natixis/Optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "import joblib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "class Optimizer:\n",
    "    \n",
    "    def __init__(self, opt_type, params):\n",
    "        \n",
    "        assert type(params) is dict, \"params must be a dict\" \n",
    "        assert opt_type in {'SGD', 'Adam'}, \"this type of optimizer is not supported\" \n",
    "        \n",
    "        self.type = opt_type\n",
    "        \n",
    "        if self.type == 'SGD':\n",
    "            for param in params:\n",
    "                assert param in {'lr', 'momentum', 'decay', 'nesterov'}, 'Illegal name of parameter'\n",
    "        elif self.type == 'Adam':\n",
    "            for param in params:\n",
    "                assert param in {'lr', 'beta_1', 'beta_2', 'epsilon', 'decay', 'amsgrad'}, 'Illegal name of parameter' \n",
    "        \n",
    "        self.params = params\n",
    "    \n",
    "    @classmethod   \n",
    "    def from_file(self, address):\n",
    "        \n",
    "        load = joblib.load(address)\n",
    "        \n",
    "        return load\n",
    "\n",
    "    def create_instance(self):\n",
    "        \n",
    "        if self.type == 'SGD':\n",
    "            return SGD(**self.params)\n",
    "        elif self.type == 'Adam':\n",
    "            return Adam(**self.params)\n",
    "        \n",
    "    def save_to_individu(self, address):\n",
    "        \n",
    "        try:\n",
    "            joblib.dump(self, address)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    def introduce_mutation(self):\n",
    "        \n",
    "        if self.type == 'SGD':\n",
    "            pass\n",
    "        elif self.type == 'Adam':\n",
    "            pass\n",
    "        \n",
    "        r = np.random.rand()\n",
    "        \n",
    "        if r < 0.15:\n",
    "            self.params['lr'] *= 2.0\n",
    "        elif r < 0.55:\n",
    "            self.params['lr'] *= 1.0\n",
    "        else:\n",
    "            self.params['lr'] *= 0.5\n",
    "            \n",
    "            \n",
    "class Task:\n",
    "    def __init__(self, ModelPath, individuPath, cnfigName):\n",
    "        \n",
    "        self.ModelPath = ModelPath \n",
    "        self.IndividuPath = individuPath\n",
    "        self.cnfigName = cnfigName \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Best_Model:\n",
    "    def __init__(self, task):\n",
    "        \n",
    "        model, specList = loadInvidualModel(task.ModelPath, task.cnfigName)\n",
    "        model2, specList2 = mutateIndividualModel(model, specList, params)\n",
    "        \n",
    "        self.parent_model = model\n",
    "        self.parent_speclist = specList\n",
    "        self.parent_weights = model.get_weights()\n",
    "        \n",
    "        self.model = model2\n",
    "        self.speclist = specList2\n",
    "        self.init_weights = model2.get_weights()\n",
    "        \n",
    "        with open(task.ModelPath + '/Best_score.txt', 'r+') as fp:\n",
    "            parent_score = float(fp.read())\n",
    "            \n",
    "        self.parent_score = parent_score\n",
    "        \n",
    "        self.task = task\n",
    "\n",
    "        #_________________updated values!_________________________________________\n",
    "        self.best_weights = model2.get_weights()\n",
    "        \n",
    "        # important!\n",
    "        self.best_score = parent_score\n",
    "\n",
    "        self.best_optimizer = None\n",
    "        self.epoch = 'Not Updated'\n",
    "        \n",
    "class CheckScoreSubmodels(tf.keras.callbacks.Callback):\n",
    "\n",
    "\n",
    "    def __init__(self, evaluate_model, best_weights, optimizer):\n",
    "        assert(type(best_weights[0]) is Best_Model)\n",
    "        \n",
    "        self.best_weights = best_weights\n",
    "        self.e_model = evaluate_model\n",
    "        self.test_generator = copy.deepcopy(TEST_GENs[len(best_weights)])\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        \n",
    "        \n",
    "        scores = self.e_model.evaluate_generator(self.test_generator)\n",
    "        print('EVALUATING SUBMODELS...', scores)\n",
    "        \n",
    "        assert(len(scores[1:]) == len(self.best_weights))\n",
    "        assert(np.allclose(scores[0], np.sum(scores[1:]), atol = 0.01))\n",
    "        \n",
    "        \n",
    "        for i in range(len(self.best_weights)):\n",
    "            \n",
    "            if self.best_weights[i].best_score > scores[i]:\n",
    "                \n",
    "                self.best_weights[i].best_weights = self.best_weights[i].model.get_weights()\n",
    "                self.best_weights[i].best_optimizer =  self.optimizer\n",
    "                self.best_weights[i].epoch = epoch\n",
    "                self.best_weights[i].best_score = scores[i]\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metamodels_create_and_train(tasks, list_optimizers, limit_tasks_by_model = params.N_MODELS_LIMIT_SIMULTANEOUSLY):\n",
    "    \n",
    "    print('N_TASKS: ', len(tasks))\n",
    "    batch_tasks = [tasks[i * limit_tasks_by_model : (i + 1) * limit_tasks_by_model]\\\n",
    "                   for i in range(len(tasks) // limit_tasks_by_model + 1)]\n",
    "    \n",
    "    TOTAL_BEST = {}\n",
    "    \n",
    "    for batch_task in batch_tasks:\n",
    "        if len(batch_task) == 0:\n",
    "            break\n",
    "        best_models = [Best_Model(task) for task in batch_task]\n",
    "        \n",
    "        for opt in list_optimizers:\n",
    "            \n",
    "            optimizer = opt.create_instance()\n",
    "            \n",
    "            list_models = [bm.model for bm in best_models]\n",
    "            \n",
    "            metamodel, eval_model = create_metamodel(list_models, optimizer)\n",
    "            \n",
    "            callbacks = [CheckScoreSubmodels(eval_model, best_models, opt)]\n",
    "\n",
    "            train_generator = copy.deepcopy(TRAIN_GENs[len(list_models)])\n",
    "            val_generator = copy.deepcopy(VAL_GENs[len(list_models)])\n",
    "            \n",
    "            fit_params = {'verbose':1, 'epochs':2, 'shuffle':False}\n",
    "            \n",
    "            print('####################### FITTING METAMODEL FOR %s#############################'%opt.type)\n",
    "            history = metamodel.fit_generator(generator = train_generator, validation_data = val_generator,\\\n",
    "                                       callbacks = callbacks, **fit_params)\n",
    "            \n",
    "            for bm in best_models:\n",
    "                bm.model.set_weights(bm.init_weights)\n",
    "        \n",
    "        for bm in best_models:\n",
    "            \n",
    "            if not bm.best_optimizer:\n",
    "                \n",
    "                bm.parent_model.set_weights(bm.parent_weights)\n",
    "                \n",
    "                with open(bm.task.IndividuPath + '/Report.txt', 'w+') as fp:\n",
    "                    fp.write('Not Evolved from ' + bm.task.ModelPath + '\\n Parent speclist: ' + str(bm.parent_speclist))\n",
    "                \n",
    "                with open(bm.task.IndividuPath + '/Best_score.txt', 'w+') as fp:\n",
    "                    fp.write(str(bm.parent_score))\n",
    "                    \n",
    "                saveIndividualModel(bm.parent_model, bm.parent_speclist, bm.task.IndividuPath, bm.task.cnfigName)\n",
    "                \n",
    "                TOTAL_BEST[bm.task.IndividuPath] = bm.best_score\n",
    "                \n",
    "            else:\n",
    "                msg = 'Evolved from '+ bm.task.ModelPath + ': ' + str(bm.parent_score) + \\\n",
    "                                    '-------> ' + str(bm.best_score) + '\\n'\n",
    "                msg = msg + 'Mutation: ' + str(bm.parent_speclist) + '-------> ' + str(bm.speclist) + '\\n'\n",
    "                \n",
    "                msg = msg + 'Best optimizer: ' + bm.best_optimizer.type + ' ' + str(bm.best_optimizer.params) + '\\n'\n",
    "                \n",
    "                msg = msg + 'Best epoch: ' + str(bm.epoch)\n",
    "                \n",
    "                with open(bm.task.IndividuPath + '/Report.txt', 'w+') as fp:\n",
    "                    fp.write(msg)\n",
    "                \n",
    "                with open(bm.task.IndividuPath + '/Best_score.txt', 'w+') as fp:\n",
    "                    fp.write(str(bm.best_score))\n",
    "                    \n",
    "                bm.model.set_weights(bm.best_weights)\n",
    "                saveIndividualModel(bm.model, bm.speclist, bm.task.IndividuPath, bm.task.cnfigName)\n",
    "                \n",
    "                TOTAL_BEST[bm.task.IndividuPath] = bm.best_score\n",
    "        \n",
    "    return TOTAL_BEST\n",
    "\n",
    "def create_metamodel(list_models, optimizer):\n",
    "    \n",
    "    inp = Input(shape = (193,))\n",
    "    \n",
    "    outs_list = [model(inp) for model in list_models]\n",
    "    \n",
    "    concat = Lambda(lambda l: K.concatenate(l, axis = -1))\n",
    "    \n",
    "    outs = concat(outs_list)\n",
    "    \n",
    "    assert(outs.shape[-1] == len(list_models))\n",
    "    assert(K.ndim(outs) == 2)\n",
    "    \n",
    "    \n",
    "    metaModel = Model(inputs = inp, outputs = outs)\n",
    "    \n",
    "    evaluate_model = Model(inputs = inp, outputs = outs_list)\n",
    "    \n",
    "    namespace = evaluate_model.output_names\n",
    "    print(evaluate_model.output_names)\n",
    "    \n",
    "    metaModel.compile(loss = 'mse', optimizer = optimizer)\n",
    "    \n",
    "    evaluate_model.compile(loss = {namespace[i] : 'mse' for i in range(len(list_models))}, optimizer = optimizer)\n",
    "    \n",
    "    return metaModel, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReinforceOptimalityWithGenetic(list_optimizers, pkgNameOriginal, pkgNameBut, InitialNbIndividual, populationctrlFunc, nbChildAllowed,\\\n",
    "                         nbloop, cnfigName, params, save = True, generate_errors = False):\n",
    "    \n",
    "    originalModelPath = params.PATH + \"/\" + pkgNameOriginal   \n",
    "\n",
    "    \n",
    "    SimuPath = params.PATH + \"/\" + pkgNameBut \n",
    "    if not(os.path.isdir(SimuPath)):\n",
    "        os.makedirs(SimuPath, 0o777)\n",
    "        \n",
    "    SimuPath = SimuPath + '/loop'\n",
    "    \n",
    "    if (os.path.isdir(SimuPath)):\n",
    "        shutil.rmtree(SimuPath)\n",
    "        \n",
    "    os.makedirs(SimuPath, 0o777 ) \n",
    "    precedingIndividualPathList =[]\n",
    "    \n",
    "    for iTimeStep in range(nbloop):\n",
    "        TimePath = SimuPath + \"/\" + \"time\" + str(iTimeStep) \n",
    "        \n",
    "        if not(os.path.isdir(TimePath)):\n",
    "                os.makedirs(TimePath, 0o777)\n",
    "                print(\"created : \",TimePath)\n",
    "                \n",
    "        LIST_OF_TASKS = []        \n",
    "        \n",
    "        if (iTimeStep == 0) :\n",
    "            for individual in range(InitialNbIndividual):\n",
    "                IndividuPath = TimePath +  \"/individu\" + str(individual)\n",
    "                \n",
    "                if not(os.path.isdir(IndividuPath)):\n",
    "                        os.makedirs(IndividuPath, 0o777)\n",
    "                        print(\"created : \",IndividuPath)\n",
    "                        \n",
    "                task = Task(originalModelPath, IndividuPath,  cnfigName)\n",
    "                \n",
    "                LIST_OF_TASKS.append(task)\n",
    "\n",
    "                precedingIndividualPathList.append(IndividuPath)                     \n",
    "        else :\n",
    "            \n",
    "            invidualpathList = []\n",
    "            individuNumero = 0\n",
    "            \n",
    "            for individualpath in precedingIndividualPathList:                            \n",
    "                \n",
    "                for child in range(nbChildAllowed): \n",
    "                    \n",
    "                    childPath = pathCreatechild(TimePath, individualpath, individuNumero)\n",
    "\n",
    "                    individuNumero += 1\n",
    "                    \n",
    "                    task = Task(individualpath, childPath, cnfigName)\n",
    "                    \n",
    "                    LIST_OF_TASKS.append(task)\n",
    "\n",
    "                    invidualpathList.append(childPath)\n",
    "                precedingIndividualPathList = invidualpathList\n",
    "           \n",
    "        K.clear_session()\n",
    "        NOTES_INDIVIDUS = metamodels_create_and_train(LIST_OF_TASKS, list_optimizers,\\\n",
    "                                limit_tasks_by_model = params.N_MODELS_LIMIT_SIMULTANEOUSLY)\n",
    "\n",
    "        SORTED_INDIVIDUS = sorted(NOTES_INDIVIDUS, key = NOTES_INDIVIDUS.__getitem__)\n",
    "        \n",
    "        N_survive = populationctrlFunc(iTimeStep)\n",
    "        bestNoteIndividus = SORTED_INDIVIDUS[:N_survive]\n",
    "        worstNoteIndividus = SORTED_INDIVIDUS[N_survive:]\n",
    "        \n",
    "        print('ListOnote=', SORTED_INDIVIDUS)\n",
    "        print('bestNoteIndexlist=', bestNoteIndividus)\n",
    "        print('worstNoteIndexlist=', worstNoteIndividus)\n",
    "        \n",
    "        for individu in worstNoteIndividus : \n",
    "            killIndividual(individu)\n",
    "            \n",
    "        precedingIndividualPathList = [individu for individu in bestNoteIndividus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created :  C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0\n",
      "created :  C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu0\n",
      "created :  C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu1\n",
      "created :  C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu2\n",
      "created :  C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu3\n",
      "N_TASKS:  4\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Test\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Test\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Test\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Test\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "['model_1', 'model_2', 'model_3', 'model_4']\n",
      "####################### FITTING METAMODEL FOR Adam#############################\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 20s 13ms/step - loss: 7.4453 - val_loss: 7.2249\n",
      "EVALUATING SUBMODELS... [29.271982211112977, 7.315879930973053, 7.311101182222366, 7.324527513980866, 7.320473586797714]\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 19s 13ms/step - loss: 7.2037 - val_loss: 7.2289\n",
      "EVALUATING SUBMODELS... [29.234349489212036, 7.305189536094666, 7.302335260868072, 7.315152735471726, 7.3116719222068784]\n",
      "['model_1', 'model_2', 'model_3', 'model_4']\n",
      "####################### FITTING METAMODEL FOR SGD#############################\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 7.9384 - val_loss: 7.3057\n",
      "EVALUATING SUBMODELS... [30.105136581420897, 7.37574533367157, 7.361796296596527, 8.059202097892761, 7.308392849445343]\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 7.1875 - val_loss: 7.2613\n",
      "EVALUATING SUBMODELS... [29.864434359550476, 7.304032819032669, 7.306036062717438, 7.948366332411766, 7.305999273300171]\n",
      "saveIndividualModel model2 at : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu0\n",
      "saveIndividualModel model2 at : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu1\n",
      "saveIndividualModel model2 at : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu2\n",
      "saveIndividualModel model2 at : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu3\n",
      "ListOnote= ['C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu2', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu1', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu3', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu0']\n",
      "bestNoteIndexlist= ['C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu2', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu1']\n",
      "worstNoteIndexlist= ['C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu3', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu0']\n",
      "killing : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu3\n",
      "killing : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu0\n",
      "created :  C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu0\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu1\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu2\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu3\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu4\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu5\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu6\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu7\n",
      "N_TASKS:  8\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu2\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu2\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu2\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu2\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu1\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu1\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu1\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu1\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "['model_1', 'model_2', 'model_3', 'model_4', 'model_5', 'model_6', 'model_7', 'model_8']\n",
      "####################### FITTING METAMODEL FOR Adam#############################\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 40s 26ms/step - loss: 7.3895 - val_loss: 7.3351\n",
      "EVALUATING SUBMODELS... [59.48351224327087, 7.307263407945633, 7.308062333106995, 7.302951067924499, 7.955269218921662, 7.308209301948548, 7.630441861391067, 7.306467270374298, 7.364847820758819]\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 7.1621 - val_loss: 7.2300\n",
      "EVALUATING SUBMODELS... [58.888983783721926, 7.312947927236557, 7.323840535640716, 7.324917555570602, 7.633589999914169, 7.325177384138107, 7.325794068336487, 7.318162099123001, 7.324554211616516]\n",
      "['model_1', 'model_2', 'model_3', 'model_4', 'model_5', 'model_6', 'model_7', 'model_8']\n",
      "####################### FITTING METAMODEL FOR SGD#############################\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 30s 20ms/step - loss: 8.3543 - val_loss: 7.4062\n",
      "EVALUATING SUBMODELS... [59.855781824111936, 7.540864836931228, 7.300769998073578, 7.350423282861709, 7.532909415721893, 7.867940439224244, 7.339876746177674, 7.572490638494491, 7.35050648522377]\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 29s 19ms/step - loss: 7.2718 - val_loss: 7.3035\n",
      "EVALUATING SUBMODELS... [59.15187417411804, 7.337573798418045, 7.303207159996033, 7.303647442102433, 7.722968242406845, 7.472249891281128, 7.3123818359375, 7.34055748295784, 7.359288558006287]\n",
      "saveIndividualModel model2 at : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu0\n",
      "saveIndividualModel model2 at : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu1\n",
      "saveIndividualModel model2 at : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu2\n",
      "saveIndividualModel model2 at : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saveIndividualModel model2 at : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu4\n",
      "saveIndividualModel model2 at : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu5\n",
      "saveIndividualModel model2 at : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu6\n",
      "saveIndividualModel model2 at : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu7\n",
      "ListOnote= ['C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu2', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu0', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu1', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu3', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu4', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu5', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu6', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu7']\n",
      "bestNoteIndexlist= ['C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu2', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu0', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu1', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu3', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu4']\n",
      "worstNoteIndexlist= ['C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu5', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu6', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu7']\n",
      "killing : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu5\n",
      "killing : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu6\n",
      "killing : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu7\n",
      "created :  C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu0\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu1\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu2\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu3\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu4\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu5\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu6\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu7\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu8\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu9\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu10\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu11\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu12\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu13\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu14\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu15\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu16\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu17\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu18\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu19\n",
      "N_TASKS:  20\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu2\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 36], [1, 30], [2, 34], [0, 12]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu2\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 36], [1, 30], [2, 34], [0, 12]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu2\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 36], [1, 30], [2, 34], [0, 12]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu2\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 36], [1, 30], [2, 34], [0, 12]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu0\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu0\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu0\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu0\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu1\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu1\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu1\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu1\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu3\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu3\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu3\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu3\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 23], [1, 25], [2, 32], [0, 11]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "['model_1', 'model_2', 'model_3', 'model_4', 'model_5', 'model_6', 'model_7', 'model_8', 'model_9', 'model_10', 'model_11', 'model_12', 'model_13', 'model_14', 'model_15', 'model_16']\n",
      "####################### FITTING METAMODEL FOR Adam#############################\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 81s 54ms/step - loss: 7.2790 - val_loss: 7.2241\n",
      "EVALUATING SUBMODELS... [117.03398741149903, 7.335950188159942, 7.302125092506409, 7.311584458351136, 7.306562292814255, 7.320051759243012, 7.307250942230224, 7.319567990779877, 7.30731241607666, 7.309106853961945, 7.344909507751465, 7.313459927082062, 7.304216254949569, 7.318464265823364, 7.311971301794052, 7.306426225423813, 7.315027478456497]\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 75s 50ms/step - loss: 7.1652 - val_loss: 7.2264\n",
      "EVALUATING SUBMODELS... [117.15159921646118, 7.323328979253769, 7.320240227222443, 7.31663668012619, 7.303219138622284, 7.3181027064323425, 7.308183276891708, 7.32484951877594, 7.324322994709015, 7.319552988290787, 7.3627709441185, 7.3221402516365055, 7.318290986061096, 7.325685246229172, 7.325850582838059, 7.317023159742355, 7.3214018914699555]\n",
      "['model_1', 'model_2', 'model_3', 'model_4', 'model_5', 'model_6', 'model_7', 'model_8', 'model_9', 'model_10', 'model_11', 'model_12', 'model_13', 'model_14', 'model_15', 'model_16']\n",
      "####################### FITTING METAMODEL FOR SGD#############################\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 53s 35ms/step - loss: 8.5802 - val_loss: 7.7672\n",
      "EVALUATING SUBMODELS... [125.06445891952515, 7.4415570647716525, 7.426650897741318, 8.430748917341232, 7.351716979265213, 7.418210819959641, 7.47552005648613, 7.538361446380615, 11.370218688726425, 7.383915351629257, 7.8994502828121185, 7.393753614425659, 7.699081637620926, 7.451758841991425, 7.963001916527748, 7.4295334649086, 7.390978332042694]\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 49s 33ms/step - loss: 7.5571 - val_loss: 7.4678\n",
      "EVALUATING SUBMODELS... [120.72080352783203, 7.368991394758225, 7.468162121295929, 7.917159508824349, 7.3114162068367, 7.3053405737876895, 7.3567103703022, 7.368878205537796, 9.480026013374328, 7.312994102478028, 7.591708541870117, 7.313926728963852, 7.368996730089187, 7.312008523702621, 7.609919243335724, 7.326417528867721, 7.3081484115123745]\n",
      "saveIndividualModel model2 at : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu0\n",
      "saveIndividualModel model2 at : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu1\n",
      "saveIndividualModel model2 at : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu2\n",
      "saveIndividualModel model2 at : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu3\n",
      "saveIndividualModel model2 at : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time2/individu4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f51ed61691e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m a = ReinforceOptimalityWithGenetic(list_optimizers, pkgNameOriginal, pkgNameBut,\\\n\u001b[1;32m---> 15\u001b[1;33m                     InitialNbIndividual, Idealpopulation, nbChildAllowed, nbloop, \"Vol\", params)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-1ec56ffdbef7>\u001b[0m in \u001b[0;36mReinforceOptimalityWithGenetic\u001b[1;34m(list_optimizers, pkgNameOriginal, pkgNameBut, InitialNbIndividual, populationctrlFunc, nbChildAllowed, nbloop, cnfigName, params, save, generate_errors)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         NOTES_INDIVIDUS = metamodels_create_and_train(LIST_OF_TASKS, list_optimizers,\\\n\u001b[1;32m---> 63\u001b[1;33m                                 limit_tasks_by_model = params.N_MODELS_LIMIT_SIMULTANEOUSLY)\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mSORTED_INDIVIDUS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNOTES_INDIVIDUS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNOTES_INDIVIDUS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-c4549779339c>\u001b[0m in \u001b[0;36mmetamodels_create_and_train\u001b[1;34m(tasks, list_optimizers, limit_tasks_by_model)\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_optimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m                 \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndividuPath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/Report.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m    506\u001b[0m                 \u001b[0mtuples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m             \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_param\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   2468\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2469\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2470\u001b[1;33m         \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1354\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nbloop = 5\n",
    "\n",
    "nbChildAllowed = 4\n",
    "pkgNameOriginal = params.LEARNINGBASE_ORIGIN\n",
    "pkgNameBut = params.LEARNINGBASE_BUT\n",
    "InitialNbIndividual = 4\n",
    "naturalSelectionPercentage = 0.5\n",
    "\n",
    "\n",
    "list_opt = [('Adam', {'lr':0.0001}), ('SGD', {'lr':0.0001})]\n",
    "list_optimizers = [Optimizer(lopt[0], lopt[1]) for lopt in list_opt]\n",
    "\n",
    "\n",
    "a = ReinforceOptimalityWithGenetic(list_optimizers, pkgNameOriginal, pkgNameBut,\\\n",
    "                    InitialNbIndividual, Idealpopulation, nbChildAllowed, nbloop, \"Vol\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(keras)\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"asdasd\".find('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
