{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys, os\n",
    "\n",
    "from sys import platform\n",
    "from decimal import *\n",
    "\n",
    "\n",
    "path='./'\n",
    "if platform == 'win32' :\n",
    "    path ='/workspace'\n",
    "    \n",
    "\n",
    "\n",
    "import keras, tensorflow, pkg_resources\n",
    "dataDirectory = 'Data'\n",
    "dataLearningFile = \"1dim_VolLoc-Example-new.CSV\"\n",
    "dataNotationFile = \"1dim_VolLoc-Example-new.CSV\"\n",
    "\n",
    "os.chdir(path)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from math import sqrt, exp, log, erf,floor\n",
    "import numpy \n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "from keras import callbacks\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "import keras.layers\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as pyplot\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import mpl_toolkits\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from IPython.display import display\n",
    "import time\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual,FloatProgress\n",
    "import ipywidgets as widgets\n",
    "import math\n",
    "import threading\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "# Generate dummy data\n",
    "\n",
    "\n",
    "\n",
    "getcontext().prec = 8\n",
    "from util_functions_YetiPhen_VolLoc import *\n",
    "\n",
    "import pkg_resources\n",
    "\n",
    "ListField1 ={\"S1\", \"mu1\", \"bonus\", \"YetiBarrier\", \"YetiCoupon\", \"PhoenixBarrier\",\"PhoenixCoupon\",\"PDIBarrier\",\"PDIGearing\",\"PDIStrike\",\"PDIType\",\n",
    "             \"maturity\",\"nbDates\"}\n",
    "\n",
    "ListField2={\"vol-date0-strike0\",\"vol-date0-strike1\",\"vol-date0-strike2\",\"vol-date0-strike3\",\"vol-date0-strike4\",\"vol-date0-strike5\",\"vol-date0-strike6\",\n",
    "           \"vol-date0-strike7\",\"vol-date0-strike8\",\"vol-date0-strike9\",\"vol-date0-strike10\",\"vol-date0-strike11\",\"vol-date0-strike12\",\"vol-date0-strike13\",\n",
    "           \"vol-date0-strike14\",\"vol-date1-strike0\",\"vol-date1-strike1\",\"vol-date1-strike2\",\"vol-date1-strike3\",\"vol-date1-strike4\",\"vol-date1-strike5\",\n",
    "           \"vol-date1-strike6\",\"vol-date1-strike7\",\"vol-date1-strike8\",\"vol-date1-strike9\",\"vol-date1-strike10\",\"vol-date1-strike11\",\"vol-date1-strike12\",\n",
    "           \"vol-date1-strike13\",\"vol-date1-strike14\",\"vol-date2-strike0\",\"vol-date2-strike1\",\"vol-date2-strike2\",\"vol-date2-strike3\",\"vol-date2-strike4\",\n",
    "           \"vol-date2-strike5\",\"vol-date2-strike6\",\"vol-date2-strike7\",\"vol-date2-strike8\",\"vol-date2-strike9\",\"vol-date2-strike10\",\"vol-date2-strike11\",\n",
    "           \"vol-date2-strike12\",\"vol-date2-strike13\",\"vol-date2-strike14\",\"vol-date3-strike0\",\"vol-date3-strike1\",\"vol-date3-strike2\",\"vol-date3-strike3\",\n",
    "           \"vol-date3-strike4\",\"vol-date3-strike5\",\"vol-date3-strike6\",\"vol-date3-strike7\",\"vol-date3-strike8\",\"vol-date3-strike9\",\"vol-date3-strike10\",\n",
    "           \"vol-date3-strike11\",\"vol-date3-strike12\",\"vol-date3-strike13\",\"vol-date3-strike14\",\"vol-date4-strike0\",\"vol-date4-strike1\",\"vol-date4-strike2\",\n",
    "           \"vol-date4-strike3\",\"vol-date4-strike4\",\"vol-date4-strike5\",\"vol-date4-strike6\",\"vol-date4-strike7\",\"vol-date4-strike8\",\"vol-date4-strike9\",\n",
    "           \"vol-date4-strike10\",\"vol-date4-strike11\",\"vol-date4-strike12\",\"vol-date4-strike13\",\"vol-date4-strike14\",\"vol-date5-strike0\",\"vol-date5-strike1\",\n",
    "           \"vol-date5-strike2\",\"vol-date5-strike3\",\"vol-date5-strike4\",\"vol-date5-strike5\",\"vol-date5-strike6\",\"vol-date5-strike7\",\"vol-date5-strike8\",\n",
    "           \"vol-date5-strike9\",\"vol-date5-strike10\",\"vol-date5-strike11\",\"vol-date5-strike12\",\"vol-date5-strike13\",\"vol-date5-strike14\",\"vol-date6-strike0\",\n",
    "           \"vol-date6-strike1\",\"vol-date6-strike2\",\"vol-date6-strike3\",\"vol-date6-strike4\",\"vol-date6-strike5\",\"vol-date6-strike6\",\"vol-date6-strike7\",\n",
    "           \"vol-date6-strike8\",\"vol-date6-strike9\",\"vol-date6-strike10\",\"vol-date6-strike11\",\"vol-date6-strike12\",\"vol-date6-strike13\",\"vol-date6-strike14\",\n",
    "           \"vol-date7-strike0\",\"vol-date7-strike1\",\"vol-date7-strike2\",\"vol-date7-strike3\",\"vol-date7-strike4\",\"vol-date7-strike5\",\"vol-date7-strike6\",\n",
    "           \"vol-date7-strike7\",\"vol-date7-strike8\",\"vol-date7-strike9\",\"vol-date7-strike10\",\"vol-date7-strike11\",\"vol-date7-strike12\",\"vol-date7-strike13\",\n",
    "           \"vol-date7-strike14\",\"vol-date8-strike0\",\"vol-date8-strike1\",\"vol-date8-strike2\",\"vol-date8-strike3\",\"vol-date8-strike4\",\"vol-date8-strike5\",\n",
    "           \"vol-date8-strike6\",\"vol-date8-strike7\",\"vol-date8-strike8\",\"vol-date8-strike9\",\"vol-date8-strike10\",\"vol-date8-strike11\",\"vol-date8-strike12\",\n",
    "           \"vol-date8-strike13\",\"vol-date8-strike14\",\"vol-date9-strike0\",\"vol-date9-strike1\",\"vol-date9-strike2\",\"vol-date9-strike3\",\"vol-date9-strike4\",\n",
    "           \"vol-date9-strike5\",\"vol-date9-strike6\",\"vol-date9-strike7\",\"vol-date9-strike8\",\"vol-date9-strike9\",\"vol-date9-strike10\",\"vol-date9-strike11\",\n",
    "           \"vol-date9-strike12\",\"vol-date9-strike13\",\"vol-date9-strike14\",\"vol-date10-strike0\",\"vol-date10-strike1\",\"vol-date10-strike2\",\"vol-date10-strike3\",\n",
    "           \"vol-date10-strike4\",\"vol-date10-strike5\",\"vol-date10-strike6\",\"vol-date10-strike7\",\"vol-date10-strike8\",\"vol-date10-strike9\",\"vol-date10-strike10\",\n",
    "           \"vol-date10-strike11\",\"vol-date10-strike12\",\"vol-date10-strike13\",\"vol-date10-strike14\",\"vol-date11-strike0\",\"vol-date11-strike1\",\"vol-date11-strike2\",\n",
    "           \"vol-date11-strike3\",\"vol-date11-strike4\",\"vol-date11-strike5\",\"vol-date11-strike6\",\"vol-date11-strike7\",\n",
    "           \"vol-date11-strike8\",\"vol-date11-strike9\",\"vol-date11-strike10\",\"vol-date11-strike11\",\"vol-date11-strike12\",\"vol-date11-strike13\",\"vol-date11-strike14\"}\n",
    "\n",
    "dataDirectory = 'Data'\n",
    "dataLearningFile = \"1dim_VolLoc-Example-new.CSV\"\n",
    "dataNotationFile = \"1dim_VolLoc-Example-new.CSV\"\n",
    "\n",
    "params = metaparameters()\n",
    "\n",
    "params.INPUT_DIM  = 193\n",
    "params.INPUT_OPTION = 193\n",
    "params.INPUT_VOL = 13\n",
    "params.NB_NEURON_PRINCIPAL = 8\n",
    "params.ACTIVATION_PRINCIPALE = 'tanh'\n",
    "params.ACTIVATION_PRINCIPALE_FINALE = 'linear'\n",
    "params.INITIAL_LEARNING_NB_EPOCH = 1000\n",
    "params.LEARNINGBASE_ORIGIN = \"New_Test\"\n",
    "params.LEARNINGBASE_BUT = \"New_Simu_Test\"\n",
    "params.GENETIC_LEARNING_NB_EPOCH = 10\n",
    "params.BATCH_SIZE_PRINCIPAL = 32768\n",
    "params.OPTIMIZER = 'adamax'##############################\n",
    "params.OPTIMIZER_GENETIC = 'SGD'###########################\n",
    "params.NBLAYERS = 11\n",
    "params.NB_LOOPS = 5\n",
    "params.PATH = path\n",
    "params.VERBOSE_FLAG = 2\n",
    "params.EPSILON_GREEDINESS = 0.25\n",
    "params.EPSILON_GREEDINESS_DECREASING_FACTOR = 0.99\n",
    "params.INITIAL_NETWORK_STRUCTURE = [[0,10], [1,20], [2,30], [0,10]]\n",
    "params.NOTATION_FILE = dataDirectory + '/' + dataNotationFile\n",
    "params.LISTFIELD1 = ListField1\n",
    "params.LISTFIELD2 = ListField2\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temps de lecture du ficher 0.03631949424743652\n",
      "temps de lecture du ficher 0.03164815902709961\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "dataframe = pandas.read_csv(dataDirectory + \"/\" + dataLearningFile)\n",
    "endTime = time.time()\n",
    "print('temps de lecture du ficher', endTime - startTime)\n",
    "X = dataframe.loc[:, ListField1.union(ListField2)];\n",
    "Y_Vol = dataframe['price'];\n",
    "datasize = X.size\n",
    "X_scaler = preprocessing.MinMaxScaler(feature_range = (0, 1))\n",
    "X_scaled = (X_scaler.fit_transform(X))\n",
    "\n",
    "params.X_scaler = X_scaler\n",
    "params.X_scaled = X_scaled\n",
    "params.X = X\n",
    "Y_scaler = preprocessing.MinMaxScaler(feature_range = (0, 1))\n",
    "Y_scaled = (Y_scaler.fit_transform(np.array(Y_Vol).reshape(-1, 1))).reshape(1, -1)[0]\n",
    "params.Y_scaler = Y_scaler\n",
    "params.Y_scaled = Y_scaled\n",
    "params.Y_Vol = Y_Vol\n",
    "\n",
    "startTime = time.time()\n",
    "dataframe = pandas.read_csv(dataDirectory + \"/\" + dataNotationFile)\n",
    "endTime = time.time()\n",
    "print('temps de lecture du ficher', endTime - startTime)\n",
    "X = dataframe.loc[:, ListField1.union(ListField2)];\n",
    "Y_Vol = dataframe['price'];\n",
    "datasize = X.size\n",
    "X_scaler = preprocessing.MinMaxScaler(feature_range = (0, 1))\n",
    "X_scaled = (X_scaler.fit_transform(X))\n",
    "params.X_Notation_scaler = X_scaler\n",
    "params.X_Notation_scaled = X_scaled\n",
    "params.X_Notation = X\n",
    "Y_scaler = preprocessing.MinMaxScaler(feature_range = (0, 1))\n",
    "Y_scaled = (Y_scaler.fit_transform(np.array(Y_Vol).reshape(-1, 1))).reshape(1, -1)[0]\n",
    "params.Y_Notation_scaler = Y_scaler\n",
    "params.Y_Notation_scaled = Y_scaled\n",
    "params.Y_Notation_Vol = Y_Vol\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator_N(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_FICHIERS, size_FICHIERS = 10000, batch_size = 20, shuffle=True, mode = 'train'):\n",
    "        'Initialization'\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.list_FICHIERS = list_FICHIERS\n",
    "        \n",
    "        self.n_fichiers = len(self.list_FICHIERS)\n",
    "        \n",
    "        self.size_fichiers = size_FICHIERS\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "                                     \n",
    "        self.mode = mode\n",
    "        \n",
    "        self.current_fichier = 0\n",
    "        # '256Ks/'+ str(self.list_FICHIERS[self.current_fichier]) +'.csv'\n",
    "        self.data = pd.read_csv(self.list_FICHIERS[self.current_fichier], sep = ';')\n",
    "        \n",
    "        self.batches_per_fichier = size_FICHIERS // batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(self.n_fichiers * self.size_fichiers / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        \n",
    "        if index // self.batches_per_fichier > self.current_fichier:\n",
    "            self.current_fichier += 1\n",
    "            # '256Ks/'+ str(self.list_FICHIERS[self.current_fichier]) +'.csv'\n",
    "            self.data = pd.read_csv(self.list_FICHIERS[self.current_fichier], sep = ';')\n",
    "            self.data = self.data.reset_index(drop = 'index')\n",
    "        \n",
    "        intra_index = index % self.batches_per_fichier\n",
    "\n",
    "        data_temp = self.data.loc[intra_index * self.batch_size : (intra_index + 1) * self.batch_size - 1]\n",
    "        \n",
    "        Y = data_temp.price.values\n",
    "        X = data_temp.drop(columns = ['nbDates', 'price']).values\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.list_FICHIERS)\n",
    "            \n",
    "        self.current_fichier = 0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to = '/workspace/FirstAttempt/Data/Sergey/'\n",
    "list_gen = [path_to + str(i) + '.csv' for i in range(5)]\n",
    "\n",
    "Train_GEN = DataGenerator_N(list_gen[:3])\n",
    "Val_GEN = DataGenerator_N(list_gen[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DataGenerator_N at 0x7fffe7520940>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "copy.deepcopy(Train_GEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Y_ordre1_Vol, model_Initial, y_scaler_Vol, y_scaled_Vol = InitialCalibration2(params.Y_Vol, \"Vol\",params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildParamList(modelspecList, params) : \n",
    "    model = buidModel(modelspecList, params)   \n",
    "    weights1 = model.get_weights()\n",
    "    return list(map(lambda k: k.shape, weights1))\n",
    "\n",
    "def CountIndividuals(a)    :\n",
    "    ii = 0\n",
    "    for f in os.listdir(a):\n",
    "        ii = ii + 1\n",
    "    return ii\n",
    "\n",
    "def convergeIndividualModel(model2):\n",
    "    print('convergeIndividualModel :')\n",
    "    return None\n",
    "   \n",
    "\n",
    "def ComputeBestNoteIndexlist(ListOfnote, populationctrlFunc, iTimeStep):\n",
    "    lenlist = len(ListOfnote)\n",
    "    sortedlist = np.argsort(ListOfnote)\n",
    "    lim = populationctrlFunc(iTimeStep)\n",
    "    lim = min(lenlist, lim)\n",
    "    print('lim=', lim)\n",
    "    ListOfWorst = sortedlist[lim:] \n",
    "    ListOfBest = sortedlist[:lim]\n",
    "    return ListOfWorst, ListOfBest\n",
    "\n",
    "def pathCreatechild(TimePath, individualpath, child):\n",
    "    pathCreated = TimePath + '/individu' +  str(child)\n",
    "    if not(os.path.isdir(pathCreated)):\n",
    "        os.makedirs(pathCreated, 0o777)\n",
    "    print('pathCreatechild=', pathCreated)\n",
    "    return pathCreated\n",
    "\n",
    "def killIndividual(individualPath):\n",
    "    print(\"killing :\", individualPath)\n",
    "    shutil.rmtree(individualPath)\n",
    "    \n",
    "def saveIndividualModel(model, X_scaler, y_scaler, y_scaled, Y_ordre1, specList, path, cnfigName):\n",
    "    model.save_weights(path + '/' + cnfigName + '.hdf5')\n",
    "    # save model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(path + '/' + cnfigName +'.json', 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # Save scaler Xand Y\n",
    "    filename = path + '/' + cnfigName + 'scalerX.pkl'\n",
    "    _= joblib.dump(X_scaler, filename, compress = 9)\n",
    "    filename = path + '/' + cnfigName + 'scalerY.pkl'\n",
    "    _= joblib.dump(y_scaler, filename, compress = 9)\n",
    "    filename = path + '/' + cnfigName + 'scaledY.pkl'\n",
    "    _= joblib.dump(y_scaled, filename, compress = 9)\n",
    "    filename = path + '/' + cnfigName + 'Y_ordre1.res'\n",
    "    _= joblib.dump(Y_ordre1, filename, compress = 9)\n",
    "    filename = path + '/' + cnfigName + 'current_structure.str'\n",
    "    _= joblib.dump(specList, filename, compress = 9)\n",
    "    print('saveIndividualModel model2 at :', path)\n",
    "\n",
    "    \n",
    "def loadInvidualModel(IndividuPath, cnfigName):\n",
    "    json_file = open(IndividuPath + \"/\" + cnfigName  + '.json', 'r')\n",
    "    file = IndividuPath + '/' + cnfigName  + '.json'\n",
    "    \n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()  \n",
    "    loaded_model = model_from_json(loaded_model_json)           \n",
    "    filename2 = IndividuPath + '/' + cnfigName  + 'current_structure.str'\n",
    "    specList = joblib.load(filename2 )\n",
    "    filename2 = IndividuPath + '/' + cnfigName  + 'scalerY.pkl'\n",
    "    y_scaler = joblib.load(filename2)\n",
    "    filename2 = IndividuPath + '/' + cnfigName  + 'scaledY.pkl'\n",
    "    y_scaled = joblib.load(filename2)\n",
    "    print('loadInvidualModel :IndividuPath=', IndividuPath)\n",
    "    return loaded_model, specList, y_scaler, y_scaled\n",
    "\n",
    "def mutateIndividualModel(model, speclist):\n",
    "    # specList = [[specList[i][0],specList[i][1]+  deltaNbNeuronList[i] ] for i in range(NbLayers)]+\n",
    "    model1 = injectionModel(model, speclist, deltaspecList, params) \n",
    "    print('mutateIndividualModel :')\n",
    "    return model1, speclist\n",
    "\n",
    "def copyModelFromInitial(originalModelPath, IndividuPath):\n",
    "    shutil.copyfile(originalModelPath + 'current_structure.str', IndividuPath + 'current_structure.str')\n",
    "    shutil.copyfile(originalModelPath + 'scalerY.pkl', IndividuPath + 'scalerY.pkl')\n",
    "    shutil.copyfile(originalModelPath + 'scaledY.pkl', IndividuPath + 'scaledY.pkl')  \n",
    "    \n",
    "def createResidues(X, X_scaler, model, y_scaler, Ycall, generate_errors):\n",
    "    Y_size = X.shape[0]\n",
    "    print(\"creating the residus for the boosting\")\n",
    "    Y_ordre1 = numpy.zeros(Ycall.size); \n",
    "    if (generate_errors):        \n",
    "        for i in range(Y_size):\n",
    "            normalizedData = X_scaler.transform(X[i].reshape(1, -1))\n",
    "            normalizedPrediction = model.predict(normalizedData)\n",
    "            outputData = y_scaler.inverse_transform(normalizedPrediction)\n",
    "            Y_ordre1[i] = outputData[0,0] - Ycall[i]\n",
    "        return Y_ordre1\n",
    "    else:\n",
    "        return Y_ordre1 \n",
    "    \n",
    "def ComputeIndividualNote(individualpath, cnfigName, params):\n",
    "    file = individualpath + '/' + cnfigName + '.json'\n",
    "    os.chdir(individualpath)\n",
    "    json_file = open(file, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()              \n",
    "    model = model_from_json(loaded_model_json)              ### chargment du model initial (1)\n",
    "    file = individualpath + '/' + cnfigName + '.hdf5'\n",
    "    model.load_weights(file)  ### chargment du model initial (2)\n",
    "    note = Compute_Note(model, params)\n",
    "    return note\n",
    "\n",
    "def Idealpopulation(nstep):\n",
    "    if (nstep < 4): \n",
    "        return 3 * nstep + 2\n",
    "    else:\n",
    "        return 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def injectionModel(model, modelspecList, deltaspecList, params, optimizer) : \n",
    "    modelspeclist2 = [[modelspecList[i][0], modelspecList[i][1] + deltaspecList[i]] for i in range(len(modelspecList))]\n",
    "    model2 = buidModel(modelspeclist2, params)\n",
    "    \n",
    "    ## debut de la recopie des poids\n",
    "    weights1 = model.get_weights()\n",
    "    param_list = list(map(lambda k: k.shape, weights1))\n",
    "    weights2 = model2.get_weights()\n",
    "    \n",
    "  ## debut de la recopie des poids\n",
    "    for iparam in range(len(param_list)):\n",
    "        w = subcopy(weights1[iparam], weights2[iparam], param_list[iparam])\n",
    "        weights2[iparam] = w  \n",
    "     \n",
    "    G = 4\n",
    "    model2 = keras.utils.multi_gpu_model(model2, gpus = G)\n",
    "    model2.compile(loss = 'mse', optimizer = optimizer, metrics = [\"mse\"])\n",
    "    model2.set_weights(weights2) \n",
    "    \n",
    "    return model2\n",
    "\n",
    "def mutateIndividualModel(model, specList, params, optimizer):\n",
    "    NbLayers = len(specList)\n",
    "    deltaNbNeuronList = BulleListPar(0, NbLayers)\n",
    "    print('mutateIndividualModel : adding neurons', deltaNbNeuronList)\n",
    "    print('specList=', specList)\n",
    "    print('deltaNbNeuronList=', deltaNbNeuronList)\n",
    "    model2 = injectionModel(model, specList, deltaNbNeuronList, params, optimizer) \n",
    "    specList2 = [[specList[i][0], specList[i][1] + deltaNbNeuronList[i]] for i in range(NbLayers)]\n",
    "    \n",
    "    return model2, specList2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OP = {'lr':0.001, 'momentum':0.01, 'decay':0.99, 'nesterov':False}\n",
    "# opt = Optimizer('SGD', OP)\n",
    "\n",
    "# joblib.dump(opt, 'C:/Users/Sergey/Desktop/Natixis/Optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_one_task(task, d_values):\n",
    "    value = task.execute()\n",
    "    d_values[task.IndividuPath] = value\n",
    "\n",
    "    \n",
    "def execute_list_of_tasks(tasks, d_values):\n",
    "    \n",
    "    for task in tasks:\n",
    "        execute_one_task(task, d_values)\n",
    "        \n",
    "    \n",
    "def EXECUTE_ALL_TASKS(LIST):\n",
    "    dict_values = {}\n",
    "    threads = []\n",
    "    \n",
    "    N_threads = 4\n",
    "    \n",
    "    '''\n",
    "    th_d = {i:[LIST[j] for j in range(len(LIST)) if j % N_threads == i] for i in range(N_threads)}\n",
    "    \n",
    "    #for task in LIST:\n",
    "    #    execute_one_task(task, dict_values)\n",
    "    \n",
    "    for i in range(N_threads):\n",
    "        \n",
    "        x = threading.Thread(target = execute_list_of_tasks, args = (th_d[i], dict_values))\n",
    "        x.daemon = True\n",
    "        threads.append(x)\n",
    "        x.start()\n",
    "    \n",
    "    for x in threads:\n",
    "        x.join()\n",
    "      \n",
    "        \n",
    "    '''\n",
    "    for task in LIST:\n",
    "        x = threading.Thread(target = execute_one_task, args = (task, dict_values))\n",
    "        \n",
    "        x.daemon = True\n",
    "        threads.append(x)\n",
    "        x.start()\n",
    "    for x in threads:\n",
    "        x.join()\n",
    "    \n",
    "    \n",
    "    return dict_values\n",
    "\n",
    "from keras.optimizers import SGD, Adam\n",
    "import joblib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "class Optimizer:\n",
    "    \n",
    "    def __init__(self, opt_type, params):\n",
    "        \n",
    "        assert type(params) is dict, \"params must be a dict\" \n",
    "        assert opt_type in {'SGD', 'Adam'}, \"this type of optimizer is not supported\" \n",
    "        \n",
    "        self.type = opt_type\n",
    "        \n",
    "        if self.type == 'SGD':\n",
    "            for param in params:\n",
    "                assert param in {'lr', 'momentum', 'decay', 'nesterov'}, 'Illegal name of parameter'\n",
    "        elif self.type == 'Adam':\n",
    "            for param in params:\n",
    "                assert param in {'lr', 'beta_1', 'beta_2', 'epsilon', 'decay', 'amsgrad'}, 'Illegal name of parameter' \n",
    "        \n",
    "        self.params = params\n",
    "    \n",
    "    @classmethod   \n",
    "    def from_file(self, address):\n",
    "        \n",
    "        load = joblib.load(address)\n",
    "        \n",
    "        return load\n",
    "\n",
    "    def create_instance(self):\n",
    "        \n",
    "        if self.type == 'SGD':\n",
    "            return SGD(**self.params)\n",
    "        elif self.type == 'Adam':\n",
    "            return Adam(**self.params)\n",
    "        \n",
    "    def save_to_individu(self, address):\n",
    "        \n",
    "        try:\n",
    "            joblib.dump(self, address)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    def introduce_mutation(self):\n",
    "        \n",
    "        if self.type == 'SGD':\n",
    "            pass\n",
    "        elif self.type == 'Adam':\n",
    "            pass\n",
    "        \n",
    "        r = np.random.rand()\n",
    "        \n",
    "        if r < 0.15:\n",
    "            self.params['lr'] *= 2.0\n",
    "        elif r < 0.55:\n",
    "            self.params['lr'] *= 1.0\n",
    "        else:\n",
    "            self.params['lr'] *= 0.5\n",
    "            \n",
    "            \n",
    "class Task:\n",
    "    def __init__(self, ModelPath, individuPath, Ycall, cnfigName, train_gen, val_gen, optimizer, **fit_params):\n",
    "        \n",
    "        #assert type(model) is list\n",
    "        assert type(optimizer) is Optimizer \n",
    "        \n",
    "        self.ModelPath = ModelPath \n",
    "        self.IndividuPath = individuPath\n",
    "        self.cnfigName = cnfigName \n",
    "        \n",
    "        self.Ycall = Ycall\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        self.fit_params = fit_params\n",
    "        \n",
    "        self.train_generator = train_gen\n",
    "        self.val_generator = val_gen\n",
    "        \n",
    "    def __evaluate(self, model):\n",
    "        score = model.evaluate_generator(self.val_generator)\n",
    "        return score[0]\n",
    "        \n",
    "    def execute(self):\n",
    "        \n",
    "        #session = tf.Session()\n",
    "        \n",
    "        with tf.Session() as session:\n",
    "            \n",
    "            K.set_session(session)\n",
    "            \n",
    "            with session.as_default():\n",
    "                with session.graph.as_default():\n",
    "\n",
    "                    opt = self.optimizer.create_instance()\n",
    "                    model, specList, y_scaler, y_scaled = loadInvidualModel(self.ModelPath, self.cnfigName)\n",
    "                    model2, specList2 = mutateIndividualModel(model, specList, params, opt)\n",
    "\n",
    "                    history = model2.fit_generator(generator = self.train_generator, validation_data = self.val_generator,\\\n",
    "                                               **self.fit_params)\n",
    "\n",
    "                    evaluation = self.__evaluate(model2)#mm.evaluate(self.evaluate_generator)\n",
    "\n",
    "                    generate_errors = False\n",
    "                    Y_ordre1 = createResidues(params.X, X_scaler, model2, y_scaler, self.Ycall, generate_errors)\n",
    "                    saveIndividualModel(model2, X_scaler, y_scaler, y_scaled, Y_ordre1, specList, self.IndividuPath, self.cnfigName)  \n",
    "                    self.optimizer.save_to_individu(self.IndividuPath + '/Optimizer')   \n",
    "        \n",
    "                #del model\n",
    "                #del model2\n",
    "                #K.clear_session()\n",
    "                #tf.reset_default_graph()\n",
    "                #gc.collect()\n",
    "\n",
    "        #session.close()\n",
    "                \n",
    "        return  evaluation# ,history.history\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReinforceOptimalityWithGenetic(train_generator, val_generator, pkgNameOriginal, pkgNameBut, InitialNbIndividual, populationctrlFunc, nbChildAllowed,\\\n",
    "                         nbloop, Ycall, cnfigName, params, save=True, generate_errors = False):\n",
    "    \n",
    "    originalModelPath = params.PATH + \"/\" + pkgNameOriginal   \n",
    "    filename = originalModelPath + '/' + cnfigName + 'scaledY.pkl'\n",
    "    y_scaled = joblib.load(filename)\n",
    "    filename = originalModelPath + '/' + cnfigName +'scalerY.pkl'\n",
    "    y_scaler = joblib.load(filename)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split( \\\n",
    "                params.X_scaled, y_scaled, test_size = 0.10, random_state = 3)\n",
    "    \n",
    "    SimuPath = params.PATH + \"/\" + pkgNameBut \n",
    "    if not(os.path.isdir(SimuPath)):\n",
    "        os.makedirs(SimuPath, 0o777)\n",
    "        \n",
    "    SimuPath = SimuPath + '/loop'\n",
    "    \n",
    "    if (os.path.isdir(SimuPath)):\n",
    "        shutil.rmtree(SimuPath)\n",
    "        \n",
    "    os.makedirs(SimuPath, 0o777 ) \n",
    "    precedingIndividualPathList =[]\n",
    "    \n",
    "    for iTimeStep in range(nbloop):\n",
    "        TimePath = SimuPath + \"/\" + \"time\" + str(iTimeStep) \n",
    "        \n",
    "        if not(os.path.isdir(TimePath)):\n",
    "                os.makedirs(TimePath, 0o777)\n",
    "                print(\"created : \",TimePath)\n",
    "                \n",
    "        LIST_OF_TASKS = []        \n",
    "        \n",
    "        if (iTimeStep == 0) :\n",
    "            for individual in range(InitialNbIndividual):\n",
    "                IndividuPath = TimePath +  \"/individu\" + str(individual)\n",
    "                \n",
    "                if not(os.path.isdir(IndividuPath)):\n",
    "                        os.makedirs(IndividuPath, 0o777)\n",
    "                        print(\"created : \",IndividuPath)\n",
    "                        \n",
    "                ## ....traitement\n",
    "                #train_generator = CREATE_GENERATOR_TRAIN()\n",
    "                #val_generator = CREATE_GENERATOR_VAL()\n",
    "                optimizer = Optimizer.from_file(params.PATH +'/' + pkgNameBut + '/Optimizer')\n",
    "                optimizer.introduce_mutation()\n",
    "                \n",
    "                train_gen = copy.deepcopy(train_generator) #DataGenerator_N()\n",
    "                val_gen = copy.deepcopy(val_generator)# DataGenerator_N()\n",
    "                \n",
    "                fp = \"/Best_weights-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "                checkpointer = keras.callbacks.ModelCheckpoint(filepath = IndividuPath + fp, verbose=1,\\\n",
    "                                                   save_best_only=True, monitor = 'loss')\n",
    "                \n",
    "                fit_params = {'epochs':2, 'verbose':0, 'callbacks': [checkpointer]}\n",
    "                \n",
    "                task = Task(originalModelPath, IndividuPath, Ycall, cnfigName, train_gen, val_gen, optimizer, **fit_params)\n",
    "                \n",
    "                LIST_OF_TASKS.append(task)\n",
    "                \n",
    "                #model, specList, y_scaler, y_scaled = loadInvidualModel(originalModelPath, cnfigName)\n",
    "                #model2, specList2 = mutateIndividualModel(model, specList, params)\n",
    "                #convergeIndividualModel(model2, params)\n",
    "                #Y_ordre1 = createResidues(params.X, X_scaler, model2, y_scaler, Ycall, generate_errors)\n",
    "                #saveIndividualModel(model2, X_scaler, y_scaler, y_scaled, Y_ordre1, specList, IndividuPath, cnfigName)   \n",
    "                ## .. Fin du traitement\n",
    "                \n",
    "                precedingIndividualPathList.append(IndividuPath)                     \n",
    "        else :\n",
    "            \n",
    "            invidualpathList = []\n",
    "            individuNumero = 0\n",
    "            \n",
    "            for individualpath in precedingIndividualPathList:                            \n",
    "            \n",
    "                #model, specList, y_scaler, y_scaled = loadInvidualModel(individualpath, cnfigName)\n",
    "                \n",
    "                for child in range(nbChildAllowed): \n",
    "                    \n",
    "                    train_gen = copy.deepcopy(train_generator) #DataGenerator_N()\n",
    "                    val_gen = copy.deepcopy(val_generator)# DataGenerator_N()\n",
    "                    \n",
    "                    childPath = pathCreatechild(TimePath, individualpath, individuNumero)\n",
    "                    \n",
    "                    fp = \"/Best_weights-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "                    checkpointer = keras.callbacks.ModelCheckpoint(filepath = childPath + fp, verbose=1,\\\n",
    "                                                   save_best_only=True, monitor = 'loss')\n",
    "                    \n",
    "                    fit_params = {'epochs':2, 'verbose':0, 'callbacks':[checkpointer]}\n",
    "                    optimizer = Optimizer.from_file(individualpath + '/Optimizer')\n",
    "                    optimizer.introduce_mutation()\n",
    "                    \n",
    "                    \n",
    "                    individuNumero += 1\n",
    "                    \n",
    "                    task = Task(individualpath, childPath, Ycall, cnfigName, train_gen, val_gen, optimizer, **fit_params)\n",
    "                    \n",
    "                    LIST_OF_TASKS.append(task)\n",
    "                    #model2,specList2 = mutateIndividualModel(model,specList,params)\n",
    "                    #convergeIndividualModel(model2,params)\n",
    "                    #Y_ordre1 = createResidues(params.X,X_scaler,model2,y_scaler,Ycall,generate_errors)\n",
    "                    #saveIndividualModel(model2,X_scaler,y_scaler,y_scaled,Y_ordre1,specList2,childPath,cnfigName)\n",
    "                    \n",
    "                    invidualpathList.append(childPath)\n",
    "                precedingIndividualPathList = invidualpathList\n",
    "                \n",
    "        NOTES_INDIVIDUS = EXECUTE_ALL_TASKS(LIST_OF_TASKS)\n",
    "        \n",
    "        ## .. Fin du traitement\n",
    "        ## .. Debut Selection Naturelle\n",
    "        ListOnote = []\n",
    "        \n",
    "        #invidualpathList = precedingIndividualPathList\n",
    "        \n",
    "        #for individualpath in invidualpathList :\n",
    "        #    note = ComputeIndividualNote(individualpath,cnfigName,params)\n",
    "        #    ListOnote.append(note)            \n",
    "            \n",
    "\n",
    "        SORTED_INDIVIDUS = sorted(NOTES_INDIVIDUS, key = NOTES_INDIVIDUS.__getitem__)\n",
    "        \n",
    "        N_survive = populationctrlFunc(iTimeStep)\n",
    "        bestNoteIndividus = SORTED_INDIVIDUS[:N_survive]\n",
    "        worstNoteIndividus = SORTED_INDIVIDUS[N_survive:]\n",
    "        \n",
    "        #worstNoteIndexlist,bestNoteIndexlist = ComputeBestNoteIndexlist(ListOnote,populationctrlFunc,iTimeStep)\n",
    "        print('ListOnote=', SORTED_INDIVIDUS)\n",
    "        print('bestNoteIndexlist=', bestNoteIndividus)\n",
    "        print('worstNoteIndexlist=', worstNoteIndividus)\n",
    "        \n",
    "        for individu in worstNoteIndividus : \n",
    "            killIndividual(individu)\n",
    "            \n",
    "        precedingIndividualPathList = [individu for individu in bestNoteIndividus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.19.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created :  .//New_Simu_Test/loop/time0\n",
      "created :  .//New_Simu_Test/loop/time0/individu0\n",
      "created :  .//New_Simu_Test/loop/time0/individu1\n",
      "created :  .//New_Simu_Test/loop/time0/individu2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0923 18:43:33.312101 140735407941376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0923 18:43:33.319065 140735407941376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0923 18:43:33.380689 140735407941376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0923 18:43:33.438957 140735407941376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0923 18:43:33.439490 140735407941376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadInvidualModel :IndividuPath= .//New_Test\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Test\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Test\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "(193, 10) (193, 23) (193, 10)\n",
      "(10,) (23,) (10,)\n",
      "(10, 20)(193, 10) (23, 25) (10, 20)\n",
      "(20,) (193, 23) (193, 10)\n",
      "(10,)  (23,) (10,)\n",
      "(10, 20) (23, 25) (10, 20)\n",
      "(20,) (25,) (20,)\n",
      "(20, 10) (25, 23) (20, 10)\n",
      "(10, 30) (23, 32) (10, 30)\n",
      "(30,) (32,) (30,)\n",
      "(10, 30) (23, 32) (10, 30)\n",
      "(30, 10) (32, 11) (30, 10)\n",
      "(10,) (11,) (10,)\n",
      "(10, 1)(25,) (20,)\n",
      "(20, 10) (25, 23) (20, 10)\n",
      "(10, 30) (23, 32) (10, 30)\n",
      "(30,) (32,) (30,)\n",
      "(10, 30) (23, 32) (10, 30)\n",
      "(30, 10) (32, 11) (30, 10)\n",
      "(10,) (11,) (10,)\n",
      "(10, 1) (11, 1) (10, 1)\n",
      "(1,) (1,) (1,)\n",
      " (11, 1) (10, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 10) (193, 23) (193, 10)\n",
      "(10,) (23,) (10,)\n",
      "(10, 20) (23, 25) (10, 20)\n",
      "(20,) (25,) (20,)\n",
      "(20, 10) (25, 23) (20, 10)\n",
      "(10, 30) (23, 32) (10, 30)\n",
      "(30,) (32,) (30,)\n",
      "(10, 30) (23, 32) (10, 30)\n",
      "(30, 10) (32, 11) (30, 10)\n",
      "(10,) (11,) (10,)\n",
      "(10, 1) (11, 1) (10, 1)\n",
      "(1,) (1,) (1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0923 18:43:36.703882 140735790913280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: loss improved from inf to 7.92994, saving model to .//New_Simu_Test/loop/time0/individu2/Best_weights-01-7.78.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 9.30090, saving model to .//New_Simu_Test/loop/time0/individu0/Best_weights-01-8.97.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 11.91578, saving model to .//New_Simu_Test/loop/time0/individu1/Best_weights-01-11.39.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 7.92994 to 7.69880, saving model to .//New_Simu_Test/loop/time0/individu2/Best_weights-02-7.73.hdf5\n",
      "\n",
      "Epoch 00002: loss did not improve from 9.30090\n",
      "\n",
      "Epoch 00002: loss improved from 11.91578 to 11.49045, saving model to .//New_Simu_Test/loop/time0/individu1/Best_weights-02-11.15.hdf5\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time0/individu2\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time0/individu0\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time0/individu1\n",
      "ListOnote= ['.//New_Simu_Test/loop/time0/individu2', './/New_Simu_Test/loop/time0/individu0', './/New_Simu_Test/loop/time0/individu1']\n",
      "bestNoteIndexlist= ['.//New_Simu_Test/loop/time0/individu2', './/New_Simu_Test/loop/time0/individu0']\n",
      "worstNoteIndexlist= ['.//New_Simu_Test/loop/time0/individu1']\n",
      "killing : .//New_Simu_Test/loop/time0/individu1\n",
      "created :  .//New_Simu_Test/loop/time1\n",
      "pathCreatechild= .//New_Simu_Test/loop/time1/individu0\n",
      "pathCreatechild= .//New_Simu_Test/loop/time1/individu1\n",
      "pathCreatechild= .//New_Simu_Test/loop/time1/individu2\n",
      "pathCreatechild= .//New_Simu_Test/loop/time1/individu3\n",
      "pathCreatechild= .//New_Simu_Test/loop/time1/individu4\n",
      "pathCreatechild= .//New_Simu_Test/loop/time1/individu5\n",
      "pathCreatechild= .//New_Simu_Test/loop/time1/individu6\n",
      "pathCreatechild= .//New_Simu_Test/loop/time1/individu7\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time0/individu2\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time0/individu2\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time0/individu2\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time0/individu2\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time0/individu0\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time0/individu0\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time0/individu0\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time0/individu0\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (193, 23) (25,)(193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,) (193, 23)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (193, 23) (193, 23)\n",
      "(25,)\n",
      "(25, 23) (23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      " (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32)(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(23, 32) (23, 32)\n",
      "(1,) (1,)(32,)  (1,)\n",
      "(32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11)  (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "\n",
      "Epoch 00001: loss improved from inf to 9.51399, saving model to .//New_Simu_Test/loop/time1/individu4/Best_weights-01-9.08.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.66803, saving model to .//New_Simu_Test/loop/time1/individu6/Best_weights-01-7.65.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.17815, saving model to .//New_Simu_Test/loop/time1/individu5/Best_weights-01-7.26.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 11.14666, saving model to .//New_Simu_Test/loop/time1/individu1/Best_weights-01-10.33.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 8.94903, saving model to .//New_Simu_Test/loop/time1/individu3/Best_weights-01-8.37.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 8.86651, saving model to .//New_Simu_Test/loop/time1/individu7/Best_weights-01-8.68.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.20886, saving model to .//New_Simu_Test/loop/time1/individu2/Best_weights-01-7.28.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 10.89887, saving model to .//New_Simu_Test/loop/time1/individu0/Best_weights-01-10.60.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 9.51399 to 9.01528, saving model to .//New_Simu_Test/loop/time1/individu4/Best_weights-02-8.90.hdf5\n",
      "\n",
      "Epoch 00002: loss did not improve from 7.66803\n",
      "\n",
      "Epoch 00002: loss improved from 11.14666 to 10.13723, saving model to .//New_Simu_Test/loop/time1/individu1/Best_weights-02-9.98.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 7.17815 to 7.13059, saving model to .//New_Simu_Test/loop/time1/individu5/Best_weights-02-7.26.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 8.86651 to 8.65438, saving model to .//New_Simu_Test/loop/time1/individu7/Best_weights-02-8.60.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 8.94903 to 8.28202, saving model to .//New_Simu_Test/loop/time1/individu3/Best_weights-02-8.17.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 10.89887 to 10.87304, saving model to .//New_Simu_Test/loop/time1/individu0/Best_weights-02-10.48.hdf5\n",
      "\n",
      "Epoch 00002: loss did not improve from 7.20886\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time1/individu6\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time1/individu4\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time1/individu1\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time1/individu3\n",
      "creating the residus for the boosting\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time1/individu7\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time1/individu5\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time1/individu2\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time1/individu0\n",
      "ListOnote= ['.//New_Simu_Test/loop/time1/individu5', './/New_Simu_Test/loop/time1/individu2', './/New_Simu_Test/loop/time1/individu6', './/New_Simu_Test/loop/time1/individu3', './/New_Simu_Test/loop/time1/individu7', './/New_Simu_Test/loop/time1/individu4', './/New_Simu_Test/loop/time1/individu1', './/New_Simu_Test/loop/time1/individu0']\n",
      "bestNoteIndexlist= ['.//New_Simu_Test/loop/time1/individu5', './/New_Simu_Test/loop/time1/individu2', './/New_Simu_Test/loop/time1/individu6', './/New_Simu_Test/loop/time1/individu3', './/New_Simu_Test/loop/time1/individu7']\n",
      "worstNoteIndexlist= ['.//New_Simu_Test/loop/time1/individu4', './/New_Simu_Test/loop/time1/individu1', './/New_Simu_Test/loop/time1/individu0']\n",
      "killing : .//New_Simu_Test/loop/time1/individu4\n",
      "killing : .//New_Simu_Test/loop/time1/individu1\n",
      "killing : .//New_Simu_Test/loop/time1/individu0\n",
      "created :  .//New_Simu_Test/loop/time2\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu0\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu1\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu2\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu3\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu4\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu5\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu6\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu7\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu8\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu9\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu10\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu11\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu12\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu13\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu14\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu15\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu16\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu17\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu18\n",
      "pathCreatechild= .//New_Simu_Test/loop/time2/individu19\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu5\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu5\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu5\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu2\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu2\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu2\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu6\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu6\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu6\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu3\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu3\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu7\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu7\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu7\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu5\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu2\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu6\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu3\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu3\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time1/individu7\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)(193, 23)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23)  (193, 23)\n",
      "(23,) (193, 23) (193, 23)\n",
      "(23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "\n",
      "(32, 11) (193, 23) (193, 23) (193, 23)\n",
      "(32, 11) (23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,)(193, 23)(193, 23)(32, 11)  (193, 23) (193, 23)\n",
      "\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      " (193, 23)(193, 23)(193, 23) (193, 23) (193, 23)\n",
      "(193, 23)(32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (193, 23)(23,) (11,)(23,) (193, 23) (193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "  (193, 23) (193, 23)\n",
      "\n",
      "(193, 23)(11,)(23,) (193, 23) (193, 23)\n",
      "(23,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(193, 23)(11, 1) (193, 23) (193, 23)\n",
      " (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32)  (11, 1) (11, 1)\n",
      "(1,) (1,)   (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,)(193, 23)(23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(23,)\n",
      " (23,) (23,)(23,)  (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(23,)\n",
      " (23,)(25,)(11, 1)(1,)\n",
      " (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(23, 25)  (11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      " (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(23,)(25,) \n",
      "(25, 23) (25, 23)  (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32)(25, 23) (23, 32) (23, 32)\n",
      "(32, 11) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(32, 11)(25, 23)  (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1)\n",
      " (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "\n",
      "Epoch 00001: loss improved from inf to 9.46575, saving model to .//New_Simu_Test/loop/time2/individu14/Best_weights-01-9.14.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 9.08282, saving model to .//New_Simu_Test/loop/time2/individu10/Best_weights-01-8.85.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.28597, saving model to .//New_Simu_Test/loop/time2/individu16/Best_weights-01-7.32.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.19752, saving model to .//New_Simu_Test/loop/time2/individu17/Best_weights-01-7.28.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.72486, saving model to .//New_Simu_Test/loop/time2/individu5/Best_weights-01-7.62.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 11.10871, saving model to .//New_Simu_Test/loop/time2/individu8/Best_weights-01-10.49.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.29203, saving model to .//New_Simu_Test/loop/time2/individu4/Best_weights-01-7.32.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.35022, saving model to .//New_Simu_Test/loop/time2/individu1/Best_weights-01-7.38.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 8.03172, saving model to .//New_Simu_Test/loop/time2/individu19/Best_weights-01-7.87.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 8.26518, saving model to .//New_Simu_Test/loop/time2/individu13/Best_weights-01-8.16.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 8.61767, saving model to .//New_Simu_Test/loop/time2/individu9/Best_weights-01-8.31.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 10.41129, saving model to .//New_Simu_Test/loop/time2/individu6/Best_weights-01-9.74.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 8.15418, saving model to .//New_Simu_Test/loop/time2/individu11/Best_weights-01-8.05.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 8.82359, saving model to .//New_Simu_Test/loop/time2/individu12/Best_weights-01-8.47.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 12.20650, saving model to .//New_Simu_Test/loop/time2/individu15/Best_weights-01-11.80.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 9.84822, saving model to .//New_Simu_Test/loop/time2/individu3/Best_weights-01-9.39.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 8.02043, saving model to .//New_Simu_Test/loop/time2/individu2/Best_weights-01-7.97.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.30806, saving model to .//New_Simu_Test/loop/time2/individu7/Best_weights-01-7.33.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.17281, saving model to .//New_Simu_Test/loop/time2/individu18/Best_weights-01-7.26.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.49127, saving model to .//New_Simu_Test/loop/time2/individu0/Best_weights-01-7.45.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 9.46575 to 9.06193, saving model to .//New_Simu_Test/loop/time2/individu14/Best_weights-02-8.94.hdf5\n",
      "\n",
      "Epoch 00002: loss did not improve from 7.29203\n",
      "\n",
      "Epoch 00002: loss improved from 9.08282 to 7.82414, saving model to .//New_Simu_Test/loop/time2/individu10/Best_weights-02-8.79.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 7.28597 to 7.22085, saving model to .//New_Simu_Test/loop/time2/individu16/Best_weights-02-7.30.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 7.72486 to 7.51408, saving model to .//New_Simu_Test/loop/time2/individu5/Best_weights-02-7.55.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 11.10871 to 10.42301, saving model to .//New_Simu_Test/loop/time2/individu8/Best_weights-02-10.21.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 7.19752 to 7.15600, saving model to .//New_Simu_Test/loop/time2/individu17/Best_weights-02-7.27.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 7.35022 to 7.19910, saving model to .//New_Simu_Test/loop/time2/individu1/Best_weights-02-7.37.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 8.03172 to 7.79533, saving model to .//New_Simu_Test/loop/time2/individu19/Best_weights-02-7.79.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 8.61767 to 8.25714, saving model to .//New_Simu_Test/loop/time2/individu9/Best_weights-02-8.16.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 8.15418 to 8.04707, saving model to .//New_Simu_Test/loop/time2/individu11/Best_weights-02-7.99.hdf5\n",
      "\n",
      "Epoch 00002: loss did not improve from 8.26518\n",
      "\n",
      "Epoch 00002: loss improved from 12.20650 to 11.69778, saving model to .//New_Simu_Test/loop/time2/individu15/Best_weights-02-11.63.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 8.82359 to 8.43024, saving model to .//New_Simu_Test/loop/time2/individu12/Best_weights-02-8.33.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 7.30806 to 7.12883, saving model to .//New_Simu_Test/loop/time2/individu7/Best_weights-02-7.36.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 9.84822 to 9.30792, saving model to .//New_Simu_Test/loop/time2/individu3/Best_weights-02-9.22.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 10.41129 to 9.61194, saving model to .//New_Simu_Test/loop/time2/individu6/Best_weights-02-9.51.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 8.02043 to 7.80089, saving model to .//New_Simu_Test/loop/time2/individu2/Best_weights-02-7.94.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 7.49127 to 7.36365, saving model to .//New_Simu_Test/loop/time2/individu0/Best_weights-02-7.45.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 7.17281 to 7.15421, saving model to .//New_Simu_Test/loop/time2/individu18/Best_weights-02-7.26.hdf5\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu13\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu4\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu14\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu17\n",
      "creating the residus for the boosting\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu10\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu8\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu16\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu5\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu1\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu11\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu7\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu9\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu19\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu15\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu12\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu3\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu2\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu6\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu0\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time2/individu18\n",
      "ListOnote= ['.//New_Simu_Test/loop/time2/individu18', './/New_Simu_Test/loop/time2/individu4', './/New_Simu_Test/loop/time2/individu17', './/New_Simu_Test/loop/time2/individu16', './/New_Simu_Test/loop/time2/individu7', './/New_Simu_Test/loop/time2/individu1', './/New_Simu_Test/loop/time2/individu0', './/New_Simu_Test/loop/time2/individu5', './/New_Simu_Test/loop/time2/individu19', './/New_Simu_Test/loop/time2/individu2', './/New_Simu_Test/loop/time2/individu11', './/New_Simu_Test/loop/time2/individu13', './/New_Simu_Test/loop/time2/individu9', './/New_Simu_Test/loop/time2/individu12', './/New_Simu_Test/loop/time2/individu10', './/New_Simu_Test/loop/time2/individu14', './/New_Simu_Test/loop/time2/individu3', './/New_Simu_Test/loop/time2/individu6', './/New_Simu_Test/loop/time2/individu8', './/New_Simu_Test/loop/time2/individu15']\n",
      "bestNoteIndexlist= ['.//New_Simu_Test/loop/time2/individu18', './/New_Simu_Test/loop/time2/individu4', './/New_Simu_Test/loop/time2/individu17', './/New_Simu_Test/loop/time2/individu16', './/New_Simu_Test/loop/time2/individu7', './/New_Simu_Test/loop/time2/individu1', './/New_Simu_Test/loop/time2/individu0', './/New_Simu_Test/loop/time2/individu5']\n",
      "worstNoteIndexlist= ['.//New_Simu_Test/loop/time2/individu19', './/New_Simu_Test/loop/time2/individu2', './/New_Simu_Test/loop/time2/individu11', './/New_Simu_Test/loop/time2/individu13', './/New_Simu_Test/loop/time2/individu9', './/New_Simu_Test/loop/time2/individu12', './/New_Simu_Test/loop/time2/individu10', './/New_Simu_Test/loop/time2/individu14', './/New_Simu_Test/loop/time2/individu3', './/New_Simu_Test/loop/time2/individu6', './/New_Simu_Test/loop/time2/individu8', './/New_Simu_Test/loop/time2/individu15']\n",
      "killing : .//New_Simu_Test/loop/time2/individu19\n",
      "killing : .//New_Simu_Test/loop/time2/individu2\n",
      "killing : .//New_Simu_Test/loop/time2/individu11\n",
      "killing : .//New_Simu_Test/loop/time2/individu13\n",
      "killing : .//New_Simu_Test/loop/time2/individu9\n",
      "killing : .//New_Simu_Test/loop/time2/individu12\n",
      "killing : .//New_Simu_Test/loop/time2/individu10\n",
      "killing : .//New_Simu_Test/loop/time2/individu14\n",
      "killing : .//New_Simu_Test/loop/time2/individu3\n",
      "killing : .//New_Simu_Test/loop/time2/individu6\n",
      "killing : .//New_Simu_Test/loop/time2/individu8\n",
      "killing : .//New_Simu_Test/loop/time2/individu15\n",
      "created :  .//New_Simu_Test/loop/time3\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu0\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu1\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu2\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu3\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu4\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu5\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu6\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu7\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu8\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu9\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu10\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu11\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu12\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu13\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu14\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu15\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu16\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu17\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu18\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu19\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu20\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu21\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu22\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu23\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu24\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu25\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu26\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu27\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu28\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu29\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu30\n",
      "pathCreatechild= .//New_Simu_Test/loop/time3/individu31\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu18\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu18\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu18\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu4\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu4\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu4\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu17\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu17\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu17\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu16\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu16\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu16\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu16\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu7\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu7\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu7\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu7\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu1\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu1\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu1\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu0\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu0\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu0\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu0\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu5\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu5\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu5\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu18\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu4\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu17\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu1\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= .//New_Simu_Test/loop/time2/individu5\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(193, 23)(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      " (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23)(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      " (193, 23)(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      " (1,) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(1,)(32,)  (32,) (32,)\n",
      "(1,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(32, 11)(23,)  (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(193, 23)(23, 32) (23, 32) (23, 32)\n",
      "(32, 11)  (193, 23) (193, 23)\n",
      "(32, 11)(23,) (32, 11)\n",
      "(11,)  (23,) (193, 23)(11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (23,)\n",
      "(23, 25) (23, 25)(193, 23)  (1,) (23, 25)(193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (25,) (25,) (25,)\n",
      "(32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23)(193, 23) (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      " (25,)(193, 23) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      " (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23)(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      " (193, 23) (193, 23)(193, 23) (193, 23)\n",
      " (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(23,)(193, 23) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(193, 23)(193, 23) (193, 23) (193, 23)(193, 23) (193, 23) (193, 23)\n",
      " (193, 23) (193, 23)\n",
      "(193, 23)(23,) (23,) (193, 23)(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1)  (193, 23) (193, 23)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(193, 23) (193, 23)(193, 23) (193, 23)(193, 23)  (193, 23) (23,) (193, 23)\n",
      "(193, 23)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23,)(193, 23)(193, 23) (193, 23)\n",
      "(23,)  (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11)(23, 32)(193, 23)(23,) (23,) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,)  (23,) (23,)\n",
      "(23, 25) (23, 25) (11, 1)(23,) (23,)(25,) (25,)\n",
      "(25, 23) (25, 23) \n",
      " (23, 32)\n",
      "  (193, 23)\n",
      " (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(23, 25)\n",
      "(193, 23)\n",
      "(32,) (32,)(193, 23) (193, 23)\n",
      " (23,)\n",
      "(23, 25) (23, 25)  (193, 23) (193, 23)\n",
      " (32,) (193, 23)\n",
      "(23,)(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23)(23,) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32)(32,)\n",
      "(25, 23)(23,) (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      " (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      " (23,) (23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      " (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      " (25, 23)\n",
      "(23, 32) (23, 32) (23, 32) (25, 23) (25, 23)(11,)(25,)(25, 23) (23, 32)(23, 25)(25, 23) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)  \n",
      "(25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "\n",
      " (23, 25) \n",
      "(11,) (11,) (32,) (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23,)(32,) (23, 32)(23, 32) (23, 32) (23, 32)(11, 1) \n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "\n",
      "(32,) (32,) (32,)(25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (11,)(25,) (25,)\n",
      "(25, 23) (25, 23)(23, 32)(11, 1) (11, 1) \n",
      "(23, 32)  (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "\n",
      "(32,) (32,) (32,) \n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(11,)(23, 32) (23, 32)\n",
      " (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(32,) (32,) (32, 11) (32, 11) (32, 11)\n",
      " (1,) (1,) (1,)\n",
      "\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(23,)\n",
      "(23, 25) (23, 25) (23, 25)\n",
      "(25,) (25,) (25,)\n",
      "(25, 23) (25, 23) (25, 23)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      " (32,) (32,)\n",
      "(23, 32) (23, 32) (23, 32)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(11,) (11,) (11,)(32,) (32,) (32,)\n",
      "(23, 32) (23, 32)(11, 1)(32,)  (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "(11, 1)\n",
      "\n",
      "(23, 32) (23, 32)\n",
      "(23, 32)(1,) (1,)  (23, 32)\n",
      "(11, 1) (1,)\n",
      "(32, 11) (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(32, 11)(11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "\n",
      "(1,) (1,) (1,)\n",
      " (32, 11) (32, 11)\n",
      "(11,) (11,) (11,)\n",
      "(11, 1) (11, 1) (11, 1)\n",
      "(1,) (1,) (1,)\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.83576, saving model to .//New_Simu_Test/loop/time3/individu4/Best_weights-01-7.76.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 11.54849, saving model to .//New_Simu_Test/loop/time3/individu30/Best_weights-01-10.67.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.14414, saving model to .//New_Simu_Test/loop/time3/individu27/Best_weights-01-7.26.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.14918, saving model to .//New_Simu_Test/loop/time3/individu31/Best_weights-01-7.26.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.30144, saving model to .//New_Simu_Test/loop/time3/individu29/Best_weights-01-7.30.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.14900, saving model to .//New_Simu_Test/loop/time3/individu0/Best_weights-01-7.26.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 10.52238, saving model to .//New_Simu_Test/loop/time3/individu7/Best_weights-01-9.80.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 8.13361, saving model to .//New_Simu_Test/loop/time3/individu11/Best_weights-01-8.03.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 12.49065, saving model to .//New_Simu_Test/loop/time3/individu9/Best_weights-01-11.96.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 12.63554, saving model to .//New_Simu_Test/loop/time3/individu10/Best_weights-01-11.81.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.15518, saving model to .//New_Simu_Test/loop/time3/individu2/Best_weights-01-7.27.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.60955, saving model to .//New_Simu_Test/loop/time3/individu21/Best_weights-01-7.60.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.22015, saving model to .//New_Simu_Test/loop/time3/individu26/Best_weights-01-7.29.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 8.14758, saving model to .//New_Simu_Test/loop/time3/individu1/Best_weights-01-7.95.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 8.20338, saving model to .//New_Simu_Test/loop/time3/individu15/Best_weights-01-7.99.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 12.74594, saving model to .//New_Simu_Test/loop/time3/individu12/Best_weights-01-12.43.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 8.32535, saving model to .//New_Simu_Test/loop/time3/individu25/Best_weights-01-8.16.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.15182, saving model to .//New_Simu_Test/loop/time3/individu22/Best_weights-01-7.26.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.14800, saving model to .//New_Simu_Test/loop/time3/individu23/Best_weights-01-7.26.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.15428, saving model to .//New_Simu_Test/loop/time3/individu8/Best_weights-01-7.26.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.18669, saving model to .//New_Simu_Test/loop/time3/individu14/Best_weights-01-7.26.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.15285, saving model to .//New_Simu_Test/loop/time3/individu17/Best_weights-01-7.26.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 9.54129, saving model to .//New_Simu_Test/loop/time3/individu5/Best_weights-01-9.19.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.54949, saving model to .//New_Simu_Test/loop/time3/individu24/Best_weights-01-7.53.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.41406, saving model to .//New_Simu_Test/loop/time3/individu16/Best_weights-01-7.37.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.94029, saving model to .//New_Simu_Test/loop/time3/individu20/Best_weights-01-7.82.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.72267, saving model to .//New_Simu_Test/loop/time3/individu13/Best_weights-01-7.67.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 8.59053, saving model to .//New_Simu_Test/loop/time3/individu3/Best_weights-01-8.36.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.18026, saving model to .//New_Simu_Test/loop/time3/individu6/Best_weights-01-7.26.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.17795, saving model to .//New_Simu_Test/loop/time3/individu18/Best_weights-01-7.26.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.44203, saving model to .//New_Simu_Test/loop/time3/individu19/Best_weights-01-7.42.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.19017, saving model to .//New_Simu_Test/loop/time3/individu28/Best_weights-01-7.26.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 11.54849 to 10.47044, saving model to .//New_Simu_Test/loop/time3/individu30/Best_weights-02-10.14.hdf5\n",
      "\n",
      "Epoch 00002: loss did not improve from 7.83576\n",
      "\n",
      "Epoch 00002: loss improved from 7.14414 to 7.13169, saving model to .//New_Simu_Test/loop/time3/individu27/Best_weights-02-7.26.hdf5\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu30\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu4\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu27\n",
      "\n",
      "Epoch 00002: loss did not improve from 7.14918\n",
      "\n",
      "Epoch 00002: loss improved from 10.52238 to 9.61499, saving model to .//New_Simu_Test/loop/time3/individu7/Best_weights-02-9.44.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 12.49065 to 11.65075, saving model to .//New_Simu_Test/loop/time3/individu9/Best_weights-02-11.73.hdf5\n",
      "\n",
      "Epoch 00002: loss did not improve from 7.14900\n",
      "\n",
      "Epoch 00002: loss improved from 7.15518 to 7.05863, saving model to .//New_Simu_Test/loop/time3/individu2/Best_weights-02-7.27.hdf5\n",
      "\n",
      "Epoch 00002: loss did not improve from 7.22015\n",
      "\n",
      "Epoch 00002: loss improved from 12.63554 to 11.72762, saving model to .//New_Simu_Test/loop/time3/individu10/Best_weights-02-11.42.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 8.13361 to 7.89594, saving model to .//New_Simu_Test/loop/time3/individu11/Best_weights-02-7.96.hdf5\n",
      "\n",
      "Epoch 00002: loss did not improve from 7.30144\n",
      "\n",
      "Epoch 00002: loss did not improve from 7.60955\n",
      "\n",
      "Epoch 00002: loss improved from 8.20338 to 7.83614, saving model to .//New_Simu_Test/loop/time3/individu15/Best_weights-02-7.90.hdf5\n",
      "\n",
      "Epoch 00002: loss did not improve from 7.14800\n",
      "\n",
      "Epoch 00002: loss did not improve from 7.15285\n",
      "\n",
      "Epoch 00002: loss improved from 12.74594 to 12.01267, saving model to .//New_Simu_Test/loop/time3/individu12/Best_weights-02-12.34.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 8.32535 to 8.16137, saving model to .//New_Simu_Test/loop/time3/individu25/Best_weights-02-8.08.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 8.14758 to 7.95101, saving model to .//New_Simu_Test/loop/time3/individu1/Best_weights-02-7.88.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 7.18026 to 7.17456, saving model to .//New_Simu_Test/loop/time3/individu6/Best_weights-02-7.30.hdf5\n",
      "\n",
      "Epoch 00002: loss did not improve from 7.15182\n",
      "\n",
      "Epoch 00002: loss improved from 9.54129 to 9.13371, saving model to .//New_Simu_Test/loop/time3/individu5/Best_weights-02-9.05.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 8.59053 to 8.29795, saving model to .//New_Simu_Test/loop/time3/individu3/Best_weights-02-8.28.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 7.18669 to 7.13761, saving model to .//New_Simu_Test/loop/time3/individu14/Best_weights-02-7.30.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 7.94029 to 7.75084, saving model to .//New_Simu_Test/loop/time3/individu20/Best_weights-02-7.78.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 7.19017 to 7.08598, saving model to .//New_Simu_Test/loop/time3/individu28/Best_weights-02-7.30.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 7.15428 to 7.15083, saving model to .//New_Simu_Test/loop/time3/individu8/Best_weights-02-7.26.hdf5\n",
      "\n",
      "Epoch 00002: loss did not improve from 7.44203\n",
      "\n",
      "Epoch 00002: loss did not improve from 7.41406\n",
      "\n",
      "Epoch 00002: loss improved from 7.72267 to 7.68980, saving model to .//New_Simu_Test/loop/time3/individu13/Best_weights-02-7.62.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 7.54949 to 7.45646, saving model to .//New_Simu_Test/loop/time3/individu24/Best_weights-02-7.52.hdf5\n",
      "\n",
      "Epoch 00002: loss did not improve from 7.17795\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu31\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu26\n",
      "creating the residus for the boosting\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu9\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu2\n",
      "creating the residus for the boosting\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu11\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu0\n",
      "saveIndividualModel model2 at : creating the residus for the boosting\n",
      ".//New_Simu_Test/loop/time3/individu7\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu10\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu29\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu17\n",
      "creating the residus for the boostingcreating the residus for the boosting\n",
      "\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu15\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu12\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu23\n",
      "creating the residus for the boosting\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu21\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu25\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu1\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu14\n",
      "creating the residus for the boosting\n",
      "creating the residus for the boosting\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu22creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu8\n",
      "\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu6\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu3\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu5\n",
      "creating the residus for the boosting\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu16\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu20\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu28\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu24\n",
      "creating the residus for the boosting\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu19\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu13\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : .//New_Simu_Test/loop/time3/individu18\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-17c34bdd8214>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m a = ReinforceOptimalityWithGenetic(Train_GEN, Val_GEN, pkgNameOriginal, pkgNameBut,\\\n\u001b[0;32m---> 11\u001b[0;31m                     InitialNbIndividual, Idealpopulation,nbChildAllowed, nbloop, Y_Vol, \"Vol\",params)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-d47395c03571>\u001b[0m in \u001b[0;36mReinforceOptimalityWithGenetic\u001b[0;34m(train_generator, val_generator, pkgNameOriginal, pkgNameBut, InitialNbIndividual, populationctrlFunc, nbChildAllowed, nbloop, Ycall, cnfigName, params, save, generate_errors)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mprecedingIndividualPathList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvidualpathList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mNOTES_INDIVIDUS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEXECUTE_ALL_TASKS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLIST_OF_TASKS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m## .. Fin du traitement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-73b861c61dd2>\u001b[0m in \u001b[0;36mEXECUTE_ALL_TASKS\u001b[0;34m(LIST)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nbloop = 5\n",
    "NbIndividual = 3\n",
    "nbChildAllowed = 4\n",
    "\n",
    "pkgNameOriginal = params.LEARNINGBASE_ORIGIN\n",
    "pkgNameBut = params.LEARNINGBASE_BUT\n",
    "InitialNbIndividual = 3\n",
    "naturalSelectionPercentage = 0.5\n",
    "\n",
    "a = ReinforceOptimalityWithGenetic(Train_GEN, Val_GEN, pkgNameOriginal, pkgNameBut,\\\n",
    "                    InitialNbIndividual, Idealpopulation,nbChildAllowed, nbloop, Y_Vol, \"Vol\",params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(keras)\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
