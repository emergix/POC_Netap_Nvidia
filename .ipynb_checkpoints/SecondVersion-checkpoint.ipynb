{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olivier/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys, os\n",
    "\n",
    "from sys import platform\n",
    "from decimal import *\n",
    "\n",
    "\n",
    "path='./'\n",
    "if platform == 'win32' :\n",
    "    path ='C:/Users/Sergey/Desktop/Natixis/Yeti'\n",
    "    path_to = 'C:/Users/Sergey/Desktop/Natixis/DataSamples/'\n",
    "if platform == 'darwin' :\n",
    "    path ='/Users/olivier/keras/NeuralPricing/A_YetiPhoenix_VolLoc'   \n",
    "    path_to = '/Users/olivier/keras/NeuralPricing/A_YetiPhoenix_VolLoc/Data/DataSamplesSerguey/'\n",
    "\n",
    "\n",
    "import keras, tensorflow, pkg_resources\n",
    "dataDirectory = 'Data'\n",
    "dataLearningFile = \"1dim_VolLoc-Example-new.CSV\"\n",
    "dataNotationFile = \"1dim_VolLoc-Example-new.CSV\"\n",
    "\n",
    "os.chdir(path)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from math import sqrt, exp, log, erf,floor\n",
    "import numpy \n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "from keras import callbacks\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "import keras.layers\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as pyplot\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import mpl_toolkits\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from IPython.display import display\n",
    "import time\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual,FloatProgress\n",
    "import ipywidgets as widgets\n",
    "import math\n",
    "import threading\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "# Generate dummy data\n",
    "\n",
    "\n",
    "\n",
    "getcontext().prec = 8\n",
    "from util_functions_YetiPhen_VolLoc import *\n",
    "\n",
    "import pkg_resources\n",
    "\n",
    "ListField1 ={\"S1\", \"mu1\", \"bonus\", \"YetiBarrier\", \"YetiCoupon\", \"PhoenixBarrier\",\"PhoenixCoupon\",\"PDIBarrier\",\"PDIGearing\",\"PDIStrike\",\"PDIType\",\n",
    "             \"maturity\",\"nbDates\"}\n",
    "\n",
    "ListField2={\"vol-date0-strike0\",\"vol-date0-strike1\",\"vol-date0-strike2\",\"vol-date0-strike3\",\"vol-date0-strike4\",\"vol-date0-strike5\",\"vol-date0-strike6\",\n",
    "           \"vol-date0-strike7\",\"vol-date0-strike8\",\"vol-date0-strike9\",\"vol-date0-strike10\",\"vol-date0-strike11\",\"vol-date0-strike12\",\"vol-date0-strike13\",\n",
    "           \"vol-date0-strike14\",\"vol-date1-strike0\",\"vol-date1-strike1\",\"vol-date1-strike2\",\"vol-date1-strike3\",\"vol-date1-strike4\",\"vol-date1-strike5\",\n",
    "           \"vol-date1-strike6\",\"vol-date1-strike7\",\"vol-date1-strike8\",\"vol-date1-strike9\",\"vol-date1-strike10\",\"vol-date1-strike11\",\"vol-date1-strike12\",\n",
    "           \"vol-date1-strike13\",\"vol-date1-strike14\",\"vol-date2-strike0\",\"vol-date2-strike1\",\"vol-date2-strike2\",\"vol-date2-strike3\",\"vol-date2-strike4\",\n",
    "           \"vol-date2-strike5\",\"vol-date2-strike6\",\"vol-date2-strike7\",\"vol-date2-strike8\",\"vol-date2-strike9\",\"vol-date2-strike10\",\"vol-date2-strike11\",\n",
    "           \"vol-date2-strike12\",\"vol-date2-strike13\",\"vol-date2-strike14\",\"vol-date3-strike0\",\"vol-date3-strike1\",\"vol-date3-strike2\",\"vol-date3-strike3\",\n",
    "           \"vol-date3-strike4\",\"vol-date3-strike5\",\"vol-date3-strike6\",\"vol-date3-strike7\",\"vol-date3-strike8\",\"vol-date3-strike9\",\"vol-date3-strike10\",\n",
    "           \"vol-date3-strike11\",\"vol-date3-strike12\",\"vol-date3-strike13\",\"vol-date3-strike14\",\"vol-date4-strike0\",\"vol-date4-strike1\",\"vol-date4-strike2\",\n",
    "           \"vol-date4-strike3\",\"vol-date4-strike4\",\"vol-date4-strike5\",\"vol-date4-strike6\",\"vol-date4-strike7\",\"vol-date4-strike8\",\"vol-date4-strike9\",\n",
    "           \"vol-date4-strike10\",\"vol-date4-strike11\",\"vol-date4-strike12\",\"vol-date4-strike13\",\"vol-date4-strike14\",\"vol-date5-strike0\",\"vol-date5-strike1\",\n",
    "           \"vol-date5-strike2\",\"vol-date5-strike3\",\"vol-date5-strike4\",\"vol-date5-strike5\",\"vol-date5-strike6\",\"vol-date5-strike7\",\"vol-date5-strike8\",\n",
    "           \"vol-date5-strike9\",\"vol-date5-strike10\",\"vol-date5-strike11\",\"vol-date5-strike12\",\"vol-date5-strike13\",\"vol-date5-strike14\",\"vol-date6-strike0\",\n",
    "           \"vol-date6-strike1\",\"vol-date6-strike2\",\"vol-date6-strike3\",\"vol-date6-strike4\",\"vol-date6-strike5\",\"vol-date6-strike6\",\"vol-date6-strike7\",\n",
    "           \"vol-date6-strike8\",\"vol-date6-strike9\",\"vol-date6-strike10\",\"vol-date6-strike11\",\"vol-date6-strike12\",\"vol-date6-strike13\",\"vol-date6-strike14\",\n",
    "           \"vol-date7-strike0\",\"vol-date7-strike1\",\"vol-date7-strike2\",\"vol-date7-strike3\",\"vol-date7-strike4\",\"vol-date7-strike5\",\"vol-date7-strike6\",\n",
    "           \"vol-date7-strike7\",\"vol-date7-strike8\",\"vol-date7-strike9\",\"vol-date7-strike10\",\"vol-date7-strike11\",\"vol-date7-strike12\",\"vol-date7-strike13\",\n",
    "           \"vol-date7-strike14\",\"vol-date8-strike0\",\"vol-date8-strike1\",\"vol-date8-strike2\",\"vol-date8-strike3\",\"vol-date8-strike4\",\"vol-date8-strike5\",\n",
    "           \"vol-date8-strike6\",\"vol-date8-strike7\",\"vol-date8-strike8\",\"vol-date8-strike9\",\"vol-date8-strike10\",\"vol-date8-strike11\",\"vol-date8-strike12\",\n",
    "           \"vol-date8-strike13\",\"vol-date8-strike14\",\"vol-date9-strike0\",\"vol-date9-strike1\",\"vol-date9-strike2\",\"vol-date9-strike3\",\"vol-date9-strike4\",\n",
    "           \"vol-date9-strike5\",\"vol-date9-strike6\",\"vol-date9-strike7\",\"vol-date9-strike8\",\"vol-date9-strike9\",\"vol-date9-strike10\",\"vol-date9-strike11\",\n",
    "           \"vol-date9-strike12\",\"vol-date9-strike13\",\"vol-date9-strike14\",\"vol-date10-strike0\",\"vol-date10-strike1\",\"vol-date10-strike2\",\"vol-date10-strike3\",\n",
    "           \"vol-date10-strike4\",\"vol-date10-strike5\",\"vol-date10-strike6\",\"vol-date10-strike7\",\"vol-date10-strike8\",\"vol-date10-strike9\",\"vol-date10-strike10\",\n",
    "           \"vol-date10-strike11\",\"vol-date10-strike12\",\"vol-date10-strike13\",\"vol-date10-strike14\",\"vol-date11-strike0\",\"vol-date11-strike1\",\"vol-date11-strike2\",\n",
    "           \"vol-date11-strike3\",\"vol-date11-strike4\",\"vol-date11-strike5\",\"vol-date11-strike6\",\"vol-date11-strike7\",\n",
    "           \"vol-date11-strike8\",\"vol-date11-strike9\",\"vol-date11-strike10\",\"vol-date11-strike11\",\"vol-date11-strike12\",\"vol-date11-strike13\",\"vol-date11-strike14\"}\n",
    "\n",
    "dataDirectory = 'Data'\n",
    "dataLearningFile = \"1dim_VolLoc-Example-new.CSV\"\n",
    "dataNotationFile = \"1dim_VolLoc-Example-new.CSV\"\n",
    "\n",
    "params = metaparameters()\n",
    "\n",
    "params.INPUT_DIM  = 193\n",
    "params.INPUT_OPTION = 193\n",
    "params.INPUT_VOL = 13\n",
    "params.NB_NEURON_PRINCIPAL = 8\n",
    "params.ACTIVATION_PRINCIPALE = 'tanh'\n",
    "params.ACTIVATION_PRINCIPALE_FINALE = 'linear'\n",
    "params.INITIAL_LEARNING_NB_EPOCH = 1000\n",
    "params.LEARNINGBASE_ORIGIN = \"New_Test\"\n",
    "params.LEARNINGBASE_BUT = \"New_Simu_Test\"\n",
    "params.GENETIC_LEARNING_NB_EPOCH = 10\n",
    "params.BATCH_SIZE_PRINCIPAL = 32768\n",
    "params.OPTIMIZER = 'adamax'##############################\n",
    "params.OPTIMIZER_GENETIC = 'SGD'###########################\n",
    "params.NBLAYERS = 11\n",
    "params.NB_LOOPS = 5\n",
    "params.PATH = path\n",
    "params.VERBOSE_FLAG = 2\n",
    "params.EPSILON_GREEDINESS = 0.25\n",
    "params.EPSILON_GREEDINESS_DECREASING_FACTOR = 0.99\n",
    "params.INITIAL_NETWORK_STRUCTURE = [[0,10], [1,20], [2,30], [0,10]]\n",
    "params.NOTATION_FILE = dataDirectory + '/' + dataNotationFile\n",
    "params.LISTFIELD1 = ListField1\n",
    "params.LISTFIELD2 = ListField2\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temps de lecture du ficher 0.055290937423706055\n",
      "temps de lecture du ficher 0.03287005424499512\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "dataframe = pandas.read_csv(dataDirectory + \"/\" + dataLearningFile)\n",
    "endTime = time.time()\n",
    "print('temps de lecture du ficher', endTime - startTime)\n",
    "X = dataframe[ListField1.union(ListField2)];\n",
    "Y_Vol = dataframe['price'];\n",
    "datasize = X.size\n",
    "X_scaler = preprocessing.MinMaxScaler(feature_range = (0, 1))\n",
    "X_scaled = (X_scaler.fit_transform(X))\n",
    "\n",
    "params.X_scaler = X_scaler\n",
    "params.X_scaled = X_scaled\n",
    "params.X = X\n",
    "Y_scaler = preprocessing.MinMaxScaler(feature_range = (0, 1))\n",
    "Y_scaled = (Y_scaler.fit_transform(np.array(Y_Vol).reshape(-1, 1))).reshape(1, -1)[0]\n",
    "params.Y_scaler = Y_scaler\n",
    "params.Y_scaled = Y_scaled\n",
    "params.Y_Vol = Y_Vol\n",
    "\n",
    "startTime = time.time()\n",
    "dataframe = pandas.read_csv(dataDirectory + \"/\" + dataNotationFile)\n",
    "endTime = time.time()\n",
    "print('temps de lecture du ficher', endTime - startTime)\n",
    "X = dataframe[ListField1.union(ListField2)];\n",
    "Y_Vol = dataframe['price'];\n",
    "datasize = X.size\n",
    "X_scaler = preprocessing.MinMaxScaler(feature_range = (0, 1))\n",
    "X_scaled = (X_scaler.fit_transform(X))\n",
    "params.X_Notation_scaler = X_scaler\n",
    "params.X_Notation_scaled = X_scaled\n",
    "params.X_Notation = X\n",
    "Y_scaler = preprocessing.MinMaxScaler(feature_range = (0, 1))\n",
    "Y_scaled = (Y_scaler.fit_transform(np.array(Y_Vol).reshape(-1, 1))).reshape(1, -1)[0]\n",
    "params.Y_Notation_scaler = Y_scaler\n",
    "params.Y_Notation_scaled = Y_scaled\n",
    "params.Y_Notation_Vol = Y_Vol\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator_N(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_FICHIERS, size_FICHIERS = 10000, batch_size = 20, shuffle=True, mode = 'train'):\n",
    "        'Initialization'\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.list_FICHIERS = list_FICHIERS\n",
    "        \n",
    "        self.n_fichiers = len(self.list_FICHIERS)\n",
    "        \n",
    "        self.size_fichiers = size_FICHIERS\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "                                     \n",
    "        self.mode = mode\n",
    "        \n",
    "        self.current_fichier = 0\n",
    "        # '256Ks/'+ str(self.list_FICHIERS[self.current_fichier]) +'.csv'\n",
    "        self.data = pd.read_csv(self.list_FICHIERS[self.current_fichier], sep = ';')\n",
    "        \n",
    "        self.batches_per_fichier = size_FICHIERS // batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(self.n_fichiers * self.size_fichiers / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        \n",
    "        if index // self.batches_per_fichier > self.current_fichier:\n",
    "            self.current_fichier += 1\n",
    "            # '256Ks/'+ str(self.list_FICHIERS[self.current_fichier]) +'.csv'\n",
    "            self.data = pd.read_csv(self.list_FICHIERS[self.current_fichier], sep = ';')\n",
    "            self.data = self.data.reset_index(drop = 'index')\n",
    "        \n",
    "        intra_index = index % self.batches_per_fichier\n",
    "\n",
    "        data_temp = self.data.loc[intra_index * self.batch_size : (intra_index + 1) * self.batch_size - 1]\n",
    "        \n",
    "        Y = data_temp.price.values\n",
    "        X = data_temp.drop(columns = ['nbDates', 'price']).values\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.list_FICHIERS)\n",
    "            \n",
    "        self.current_fichier = 0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_gen = [path_to + str(i) + '.csv' for i in range(5)]\n",
    "\n",
    "Train_GEN = DataGenerator_N(list_gen[:3])\n",
    "Val_GEN = DataGenerator_N(list_gen[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DataGenerator_N at 0x20094f22320>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "copy.deepcopy(Train_GEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Y_ordre1_Vol, model_Initial, y_scaler_Vol, y_scaled_Vol = InitialCalibration2(params.Y_Vol, \"Vol\",params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildParamList(modelspecList, params) : \n",
    "    model = buidModel(modelspecList, params)   \n",
    "    weights1 = model.get_weights()\n",
    "    return list(map(lambda k: k.shape, weights1))\n",
    "\n",
    "def CountIndividuals(a)    :\n",
    "    ii = 0\n",
    "    for f in os.listdir(a):\n",
    "        ii = ii + 1\n",
    "    return ii\n",
    "\n",
    "def convergeIndividualModel(model2):\n",
    "    print('convergeIndividualModel :')\n",
    "    return None\n",
    "   \n",
    "\n",
    "def ComputeBestNoteIndexlist(ListOfnote, populationctrlFunc, iTimeStep):\n",
    "    lenlist = len(ListOfnote)\n",
    "    sortedlist = np.argsort(ListOfnote)\n",
    "    lim = populationctrlFunc(iTimeStep)\n",
    "    lim = min(lenlist, lim)\n",
    "    print('lim=', lim)\n",
    "    ListOfWorst = sortedlist[lim:] \n",
    "    ListOfBest = sortedlist[:lim]\n",
    "    return ListOfWorst, ListOfBest\n",
    "\n",
    "def pathCreatechild(TimePath, individualpath, child):\n",
    "    pathCreated = TimePath + '/individu' +  str(child)\n",
    "    if not(os.path.isdir(pathCreated)):\n",
    "        os.makedirs(pathCreated, 0o777)\n",
    "    print('pathCreatechild=', pathCreated)\n",
    "    return pathCreated\n",
    "\n",
    "def killIndividual(individualPath):\n",
    "    print(\"killing :\", individualPath)\n",
    "    shutil.rmtree(individualPath)\n",
    "    \n",
    "def saveIndividualModel(model, X_scaler, y_scaler, y_scaled, Y_ordre1, specList, path, cnfigName):\n",
    "    model.save_weights(path + '/' + cnfigName + '.hdf5')\n",
    "    # save model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(path + '/' + cnfigName +'.json', 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # Save scaler Xand Y\n",
    "    filename = path + '/' + cnfigName + 'scalerX.pkl'\n",
    "    _= joblib.dump(X_scaler, filename, compress = 9)\n",
    "    filename = path + '/' + cnfigName + 'scalerY.pkl'\n",
    "    _= joblib.dump(y_scaler, filename, compress = 9)\n",
    "    filename = path + '/' + cnfigName + 'scaledY.pkl'\n",
    "    _= joblib.dump(y_scaled, filename, compress = 9)\n",
    "    filename = path + '/' + cnfigName + 'Y_ordre1.res'\n",
    "    _= joblib.dump(Y_ordre1, filename, compress = 9)\n",
    "    filename = path + '/' + cnfigName + 'current_structure.str'\n",
    "    _= joblib.dump(specList, filename, compress = 9)\n",
    "    print('saveIndividualModel model2 at :', path)\n",
    "\n",
    "    \n",
    "def loadInvidualModel(IndividuPath, cnfigName):\n",
    "    json_file = open(IndividuPath + \"/\" + cnfigName  + '.json', 'r')\n",
    "    file = IndividuPath + '/' + cnfigName  + '.json'\n",
    "    \n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()  \n",
    "    loaded_model = model_from_json(loaded_model_json)           \n",
    "    filename2 = IndividuPath + '/' + cnfigName  + 'current_structure.str'\n",
    "    specList = joblib.load(filename2 )\n",
    "    filename2 = IndividuPath + '/' + cnfigName  + 'scalerY.pkl'\n",
    "    y_scaler = joblib.load(filename2)\n",
    "    filename2 = IndividuPath + '/' + cnfigName  + 'scaledY.pkl'\n",
    "    y_scaled = joblib.load(filename2)\n",
    "    print('loadInvidualModel :IndividuPath=', IndividuPath)\n",
    "    return loaded_model, specList, y_scaler, y_scaled\n",
    "\n",
    "def mutateIndividualModel(model, speclist):\n",
    "    # specList = [[specList[i][0],specList[i][1]+  deltaNbNeuronList[i] ] for i in range(NbLayers)]+\n",
    "    model1 = injectionModel(model, speclist, deltaspecList, params) \n",
    "    print('mutateIndividualModel :')\n",
    "    return model1, speclist\n",
    "\n",
    "def copyModelFromInitial(originalModelPath, IndividuPath):\n",
    "    shutil.copyfile(originalModelPath + 'current_structure.str', IndividuPath + 'current_structure.str')\n",
    "    shutil.copyfile(originalModelPath + 'scalerY.pkl', IndividuPath + 'scalerY.pkl')\n",
    "    shutil.copyfile(originalModelPath + 'scaledY.pkl', IndividuPath + 'scaledY.pkl')  \n",
    "    \n",
    "def createResidues(X, X_scaler, model, y_scaler, Ycall, generate_errors):\n",
    "    Y_size = X.shape[0]\n",
    "    print(\"creating the residus for the boosting\")\n",
    "    Y_ordre1 = numpy.zeros(Ycall.size); \n",
    "    if (generate_errors):        \n",
    "        for i in range(Y_size):\n",
    "            normalizedData = X_scaler.transform(X[i].reshape(1, -1))\n",
    "            normalizedPrediction = model.predict(normalizedData)\n",
    "            outputData = y_scaler.inverse_transform(normalizedPrediction)\n",
    "            Y_ordre1[i] = outputData[0,0] - Ycall[i]\n",
    "        return Y_ordre1\n",
    "    else:\n",
    "        return Y_ordre1 \n",
    "    \n",
    "def ComputeIndividualNote(individualpath, cnfigName, params):\n",
    "    file = individualpath + '/' + cnfigName + '.json'\n",
    "    os.chdir(individualpath)\n",
    "    json_file = open(file, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()              \n",
    "    model = model_from_json(loaded_model_json)              ### chargment du model initial (1)\n",
    "    file = individualpath + '/' + cnfigName + '.hdf5'\n",
    "    model.load_weights(file)  ### chargment du model initial (2)\n",
    "    note = Compute_Note(model, params)\n",
    "    return note\n",
    "\n",
    "def Idealpopulation(nstep):\n",
    "    if (nstep < 4): \n",
    "        return 3 * nstep + 2\n",
    "    else:\n",
    "        return 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def injectionModel(model, modelspecList, deltaspecList, params, optimizer) : \n",
    "    modelspeclist2 = [[modelspecList[i][0], modelspecList[i][1] + deltaspecList[i]] for i in range(len(modelspecList))]\n",
    "    model2 = buidModel(modelspeclist2, params)\n",
    "    \n",
    "    ## debut de la recopie des poids\n",
    "    weights1 = model.get_weights()\n",
    "    param_list = list(map(lambda k: k.shape, weights1))\n",
    "    weights2 = model2.get_weights()\n",
    "    \n",
    "  ## debut de la recopie des poids\n",
    "    for iparam in range(len(param_list)):\n",
    "        w = subcopy(weights1[iparam], weights2[iparam], param_list[iparam])\n",
    "        weights2[iparam] = w  \n",
    "     \n",
    "    G = 1\n",
    "    #model2 = keras.utils.multi_gpu_model(model2, gpus = G)\n",
    "    model2.compile(loss = 'mse', optimizer = optimizer, metrics = [\"mse\"])\n",
    "    model2.set_weights(weights2) \n",
    "    \n",
    "    return model2\n",
    "\n",
    "def mutateIndividualModel(model, specList, params, optimizer):\n",
    "    NbLayers = len(specList)\n",
    "    deltaNbNeuronList = BulleListPar(0, NbLayers)\n",
    "    print('mutateIndividualModel : adding neurons', deltaNbNeuronList)\n",
    "    print('specList=', specList)\n",
    "    print('deltaNbNeuronList=', deltaNbNeuronList)\n",
    "    model2 = injectionModel(model, specList, deltaNbNeuronList, params, optimizer) \n",
    "    specList2 = [[specList[i][0], specList[i][1] + deltaNbNeuronList[i]] for i in range(NbLayers)]\n",
    "    \n",
    "    return model2, specList2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OP = {'lr':0.001, 'momentum':0.01, 'decay':0.99, 'nesterov':False}\n",
    "# opt = Optimizer('SGD', OP)\n",
    "\n",
    "# joblib.dump(opt, 'C:/Users/Sergey/Desktop/Natixis/Optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_one_task(task, d_values):\n",
    "    value = task.execute()\n",
    "    d_values[task.IndividuPath] = value\n",
    "\n",
    "def EXECUTE_ALL_TASKS(LIST):\n",
    "    dict_values = {}\n",
    "    threads = []\n",
    "    \n",
    "    for task in LIST:\n",
    "        x = threading.Thread(target = execute_one_task, args = (task, dict_values))\n",
    "        x.start()\n",
    "        threads.append(x)\n",
    "    for x in threads:\n",
    "        x.join()\n",
    "        \n",
    "    return dict_values\n",
    "\n",
    "from keras.optimizers import SGD, Adam\n",
    "import joblib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "class Optimizer:\n",
    "    \n",
    "    def __init__(self, opt_type, params):\n",
    "        \n",
    "        assert type(params) is dict, \"params must be a dict\" \n",
    "        assert opt_type in {'SGD', 'Adam'}, \"this type of optimizer is not supported\" \n",
    "        \n",
    "        self.type = opt_type\n",
    "        \n",
    "        if self.type == 'SGD':\n",
    "            for param in params:\n",
    "                assert param in {'lr', 'momentum', 'decay', 'nesterov'}, 'Illegal name of parameter'\n",
    "        elif self.type == 'Adam':\n",
    "            for param in params:\n",
    "                assert param in {'lr', 'beta_1', 'beta_2', 'epsilon', 'decay', 'amsgrad'}, 'Illegal name of parameter' \n",
    "        \n",
    "        self.params = params\n",
    "    \n",
    "    @classmethod   \n",
    "    def from_file(self, address):\n",
    "        \n",
    "        load = joblib.load(address)\n",
    "        \n",
    "        return load\n",
    "\n",
    "    def create_instance(self):\n",
    "        \n",
    "        if self.type == 'SGD':\n",
    "            return SGD(**self.params)\n",
    "        elif self.type == 'Adam':\n",
    "            return Adam(**self.params)\n",
    "        \n",
    "    def save_to_individu(self, address):\n",
    "        \n",
    "        try:\n",
    "            joblib.dump(self, address)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    def introduce_mutation(self):\n",
    "        \n",
    "        if self.type == 'SGD':\n",
    "            pass\n",
    "        elif self.type == 'Adam':\n",
    "            pass\n",
    "        \n",
    "        r = np.random.rand()\n",
    "        \n",
    "        if r < 0.15:\n",
    "            self.params['lr'] *= 2.0\n",
    "        elif r < 0.55:\n",
    "            self.params['lr'] *= 1.0\n",
    "        else:\n",
    "            self.params['lr'] *= 0.5\n",
    "            \n",
    "            \n",
    "class Task:\n",
    "    def __init__(self, ModelPath, individuPath, Ycall, cnfigName, train_gen, val_gen, optimizer, **fit_params):\n",
    "        \n",
    "        #assert type(model) is list\n",
    "        assert type(optimizer) is Optimizer \n",
    "        \n",
    "        self.ModelPath = ModelPath \n",
    "        self.IndividuPath = individuPath\n",
    "        self.cnfigName = cnfigName \n",
    "        \n",
    "        self.Ycall = Ycall\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        self.fit_params = fit_params\n",
    "        \n",
    "        self.train_generator = train_gen\n",
    "        self.val_generator = val_gen\n",
    "        \n",
    "    def __evaluate(self, model):\n",
    "        score = model.evaluate_generator(self.val_generator)\n",
    "        return score[0]\n",
    "        \n",
    "    def execute(self):\n",
    "        \n",
    "        session = tf.Session()\n",
    "        K.set_session(session)\n",
    "    \n",
    "        with session.as_default():\n",
    "            with session.graph.as_default():\n",
    "                \n",
    "                opt = self.optimizer.create_instance()\n",
    "                model, specList, y_scaler, y_scaled = loadInvidualModel(self.ModelPath, self.cnfigName)\n",
    "                model2, specList2 = mutateIndividualModel(model, specList, params, opt)\n",
    "                \n",
    "                history = model2.fit_generator(generator = self.train_generator, validation_data = self.val_generator,\\\n",
    "                                           **self.fit_params)\n",
    "                \n",
    "                evaluation = self.__evaluate(model2)#mm.evaluate(self.evaluate_generator)\n",
    "                \n",
    "                generate_errors = False\n",
    "                Y_ordre1 = createResidues(params.X, X_scaler, model2, y_scaler, self.Ycall, generate_errors)\n",
    "                saveIndividualModel(model2, X_scaler, y_scaler, y_scaled, Y_ordre1, specList, self.IndividuPath, self.cnfigName)  \n",
    "                self.optimizer.save_to_individu(self.IndividuPath + '/Optimizer')   \n",
    "        \n",
    "        del model\n",
    "        del model2\n",
    "        K.clear_session()\n",
    "        tf.reset_default_graph()\n",
    "        gc.collect()\n",
    "        session.close()\n",
    "                \n",
    "        return  evaluation# ,history.history\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReinforceOptimalityWithGenetic(train_generator, val_generator, pkgNameOriginal, pkgNameBut, InitialNbIndividual, populationctrlFunc, nbChildAllowed,\\\n",
    "                         nbloop, Ycall, cnfigName, params, save=True, generate_errors = False):\n",
    "    \n",
    "    originalModelPath = params.PATH + \"/\" + pkgNameOriginal   \n",
    "    filename = originalModelPath + '/' + cnfigName + 'scaledY.pkl'\n",
    "    y_scaled = joblib.load(filename)\n",
    "    filename = originalModelPath + '/' + cnfigName +'scalerY.pkl'\n",
    "    y_scaler = joblib.load(filename)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split( \\\n",
    "                params.X_scaled, y_scaled, test_size = 0.10, random_state = 3)\n",
    "    \n",
    "    SimuPath = params.PATH + \"/\" + pkgNameBut \n",
    "    if not(os.path.isdir(SimuPath)):\n",
    "        os.makedirs(SimuPath, 0o777)\n",
    "        \n",
    "    SimuPath = SimuPath + '/loop'\n",
    "    \n",
    "    if (os.path.isdir(SimuPath)):\n",
    "        shutil.rmtree(SimuPath)\n",
    "        \n",
    "    os.makedirs(SimuPath, 0o777 ) \n",
    "    precedingIndividualPathList =[]\n",
    "    \n",
    "    for iTimeStep in range(nbloop):\n",
    "        TimePath = SimuPath + \"/\" + \"time\" + str(iTimeStep) \n",
    "        \n",
    "        if not(os.path.isdir(TimePath)):\n",
    "                os.makedirs(TimePath, 0o777)\n",
    "                print(\"created : \",TimePath)\n",
    "                \n",
    "        LIST_OF_TASKS = []        \n",
    "        \n",
    "        if (iTimeStep == 0) :\n",
    "            for individual in range(InitialNbIndividual):\n",
    "                IndividuPath = TimePath +  \"/individu\" + str(individual)\n",
    "                \n",
    "                if not(os.path.isdir(IndividuPath)):\n",
    "                        os.makedirs(IndividuPath, 0o777)\n",
    "                        print(\"created : \",IndividuPath)\n",
    "                        \n",
    "                ## ....traitement\n",
    "                #train_generator = CREATE_GENERATOR_TRAIN()\n",
    "                #val_generator = CREATE_GENERATOR_VAL()\n",
    "                optimizer = Optimizer.from_file(params.PATH +'/' + pkgNameBut + '/Optimizer')\n",
    "                optimizer.introduce_mutation()\n",
    "                \n",
    "                train_gen = copy.deepcopy(train_generator) #DataGenerator_N()\n",
    "                val_gen = copy.deepcopy(val_generator)# DataGenerator_N()\n",
    "                \n",
    "                checkpointer = keras.callbacks.ModelCheckpoint(filepath = IndividuPath + \"/BestWeights.hdf5\",verbose=1,\\\n",
    "                                                   save_best_only=True , monitor = 'loss')\n",
    "                \n",
    "                fit_params = {'epochs':2, 'verbose':1, 'callbacks': [checkpointer]}\n",
    "                \n",
    "                task = Task(originalModelPath, IndividuPath, Ycall, cnfigName, train_gen, val_gen, optimizer, **fit_params)\n",
    "                \n",
    "                LIST_OF_TASKS.append(task)\n",
    "                \n",
    "                #model, specList, y_scaler, y_scaled = loadInvidualModel(originalModelPath, cnfigName)\n",
    "                #model2, specList2 = mutateIndividualModel(model, specList, params)\n",
    "                #convergeIndividualModel(model2, params)\n",
    "                #Y_ordre1 = createResidues(params.X, X_scaler, model2, y_scaler, Ycall, generate_errors)\n",
    "                #saveIndividualModel(model2, X_scaler, y_scaler, y_scaled, Y_ordre1, specList, IndividuPath, cnfigName)   \n",
    "                ## .. Fin du traitement\n",
    "                \n",
    "                precedingIndividualPathList.append(IndividuPath)                     \n",
    "        else :\n",
    "            \n",
    "            invidualpathList = []\n",
    "            individuNumero = 0\n",
    "            \n",
    "            for individualpath in precedingIndividualPathList:                            \n",
    "            \n",
    "                #model, specList, y_scaler, y_scaled = loadInvidualModel(individualpath, cnfigName)\n",
    "                \n",
    "                for child in range(nbChildAllowed): \n",
    "                    \n",
    "                    train_gen = copy.deepcopy(train_generator) #DataGenerator_N()\n",
    "                    val_gen = copy.deepcopy(val_generator)# DataGenerator_N()\n",
    "                    \n",
    "                    checkpointer = keras.callbacks.ModelCheckpoint(filepath = individualpath + \"/BestWeights.hdf5\",verbose=1,\\\n",
    "                                                   save_best_only=True , monitor = 'loss')\n",
    "                    \n",
    "                    fit_params = {'epochs':2, 'verbose':1, 'callbacks':[checkpointer]}\n",
    "                    optimizer = Optimizer.from_file(individualpath + '/Optimizer')\n",
    "                    optimizer.introduce_mutation()\n",
    "                    \n",
    "                    childPath = pathCreatechild(TimePath, individualpath, individuNumero)\n",
    "                    individuNumero += 1\n",
    "                    \n",
    "                    task = Task(individualpath, childPath, Ycall, cnfigName, train_gen, val_gen, optimizer, **fit_params)\n",
    "                    \n",
    "                    LIST_OF_TASKS.append(task)\n",
    "                    #model2,specList2 = mutateIndividualModel(model,specList,params)\n",
    "                    #convergeIndividualModel(model2,params)\n",
    "                    #Y_ordre1 = createResidues(params.X,X_scaler,model2,y_scaler,Ycall,generate_errors)\n",
    "                    #saveIndividualModel(model2,X_scaler,y_scaler,y_scaled,Y_ordre1,specList2,childPath,cnfigName)\n",
    "                    \n",
    "                    invidualpathList.append(childPath)\n",
    "                precedingIndividualPathList = invidualpathList\n",
    "                \n",
    "        NOTES_INDIVIDUS = EXECUTE_ALL_TASKS(LIST_OF_TASKS)\n",
    "        \n",
    "        ## .. Fin du traitement\n",
    "        ## .. Debut Selection Naturelle\n",
    "        ListOnote = []\n",
    "        \n",
    "        #invidualpathList = precedingIndividualPathList\n",
    "        \n",
    "        #for individualpath in invidualpathList :\n",
    "        #    note = ComputeIndividualNote(individualpath,cnfigName,params)\n",
    "        #    ListOnote.append(note)\n",
    "        \n",
    "        SORTED_INDIVIDUS = sorted(NOTES_INDIVIDUS, key = NOTES_INDIVIDUS.__getitem__)\n",
    "        \n",
    "        N_survive = populationctrlFunc(iTimeStep)\n",
    "        bestNoteIndividus = SORTED_INDIVIDUS[:N_survive]\n",
    "        worstNoteIndividus = SORTED_INDIVIDUS[N_survive:]\n",
    "        \n",
    "        #worstNoteIndexlist,bestNoteIndexlist = ComputeBestNoteIndexlist(ListOnote,populationctrlFunc,iTimeStep)\n",
    "        print('ListOnote=', SORTED_INDIVIDUS)\n",
    "        print('bestNoteIndexlist=', bestNoteIndividus)\n",
    "        print('worstNoteIndexlist=', worstNoteIndividus)\n",
    "        \n",
    "        for individu in worstNoteIndividus : \n",
    "            killIndividual(individu)\n",
    "            \n",
    "        precedingIndividualPathList = [individu for individu in bestNoteIndividus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created :  C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0\n",
      "created :  C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu0\n",
      "created :  C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu1\n",
      "created :  C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu2\n",
      "WARNING:tensorflow:From C:\\Users\\Sergey\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Sergey\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Test\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "WARNING:tensorflow:From C:\\Users\\Sergey\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Test\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Test\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "WARNING:tensorflow:From C:\\Users\\Sergey\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Sergey\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Sergey\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Sergey\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/2Epoch 1/2\n",
      "\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 20s 14ms/step - loss: 8.4216 - mean_squared_error: 8.4216 - val_loss: 8.2040 - val_mean_squared_error: 8.2040\n",
      "\n",
      "Epoch 00001: loss improved from inf to 8.42155, saving model to C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu0/BestWeights.hdf5\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 9.4455 - mean_squared_error: 9.4455 - val_loss: 9.2763 - val_mean_squared_error: 9.2763\n",
      "\n",
      "Epoch 00001: loss improved from inf to 9.44548, saving model to C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu1/BestWeights.hdf5\n",
      " 272/1500 [====>.........................] - ETA: 10s - loss: 8.1213 - mean_squared_error: 8.1213Epoch 2/2\n",
      "1500/1500 [==============================] - 24s 16ms/step - loss: 8.6683 - mean_squared_error: 8.6683 - val_loss: 8.4644 - val_mean_squared_error: 8.4644\n",
      "\n",
      "Epoch 00001: loss improved from inf to 8.66832, saving model to C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu2/BestWeights.hdf5\n",
      " - ETA: 15s - loss: 8.9096 - mean_squared_error: 8.9096 loss: 7.9035 - mean_squared_error: 7.903 380/1500 [======>.......................] - ETA: 10s - loss: 7.8723 - mean_squared_error: 7.8723Epoch 2/2\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 7.9784 - mean_squared_error: 7.9784 - val_loss: 8.0718 - val_mean_squared_error: 8.0718\n",
      "\n",
      "Epoch 00002: loss improved from 8.42155 to 7.97841, saving model to C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu0/BestWeights.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sergey\\Anaconda3\\lib\\threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Sergey\\Anaconda3\\lib\\threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-10-63305f095eaf>\", line 2, in execute_one_task\n",
      "    value = task.execute()\n",
      "  File \"<ipython-input-10-63305f095eaf>\", line 115, in execute\n",
      "    **self.fit_params)\n",
      "  File \"C:\\Users\\Sergey\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Sergey\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1418, in fit_generator\n",
      "    initial_epoch=initial_epoch)\n",
      "  File \"C:\\Users\\Sergey\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\", line 234, in fit_generator\n",
      "    workers=0)\n",
      "  File \"C:\\Users\\Sergey\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Sergey\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1472, in evaluate_generator\n",
      "    verbose=verbose)\n",
      "  File \"C:\\Users\\Sergey\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\", line 330, in evaluate_generator\n",
      "    generator_output = next(output_generator)\n",
      "  File \"C:\\Users\\Sergey\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 601, in get\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"C:\\Users\\Sergey\\Anaconda3\\lib\\site-packages\\six.py\", line 693, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\Sergey\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 595, in get\n",
      "    inputs = self.queue.get(block=True).get()\n",
      "  File \"C:\\Users\\Sergey\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 657, in get\n",
      "    raise self._value\n",
      "  File \"C:\\Users\\Sergey\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"C:\\Users\\Sergey\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 20s 14ms/step - loss: 9.2516 - mean_squared_error: 9.2516 - val_loss: 9.1926 - val_mean_squared_error: 9.1926\n",
      "\n",
      "Epoch 00002: loss improved from 9.44548 to 9.25161, saving model to C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu1/BestWeights.hdf5\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu0\n",
      "creating the residus for the boosting\n",
      "saveIndividualModel model2 at : C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu1\n",
      "ListOnote= ['C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu0', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu1']\n",
      "bestNoteIndexlist= ['C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu0', 'C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu1']\n",
      "worstNoteIndexlist= []\n",
      "created :  C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu0\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu1\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu2\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu3\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu4\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu5\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu6\n",
      "pathCreatechild= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time1/individu7\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu0\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu0\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu0\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu0\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu1\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu1\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu1\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n",
      "loadInvidualModel :IndividuPath= C:/Users/Sergey/Desktop/Natixis/Yeti/New_Simu_Test/loop/time0/individu1\n",
      "mutateIndividualModel : adding neurons [13, 5, 2, 1]\n",
      "specList= [[0, 10], [1, 20], [2, 30], [0, 10]]\n",
      "deltaNbNeuronList= [13, 5, 2, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function BaseSession._Callable.__del__ at 0x0000020098D49D90>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sergey\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1473, in __del__\n",
      "    self._session._session, self._handle)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n",
      "Exception ignored in: <function BaseSession._Callable.__del__ at 0x0000020098D49D90>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sergey\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1473, in __del__\n",
      "    self._session._session, self._handle)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Epoch 1/2\n",
      "Epoch 1/2\n",
      "Epoch 1/2\n",
      "Epoch 1/2\n",
      "Epoch 1/2\n",
      "Epoch 1/2\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 102/1500 [=>............................] - ETA: 1:55 - loss: 17.7061 - mean_squared_error: 17.7061s: 8.9522 - mean_squared_error: 8.9522474509/1500 [===>..........................]d_error: 8.2403  A: 58:08 - l - ETA: 1:44 - loss: 9.5849 - mean_squared_error: 9.5849  75/1500 [>.............................] - ETA: 1:16 - loss: 8.6915 - mean_squared_er  81/1500 [>..............  41/1500 [............................ - ETA: 58s - loss: 8.1389 - mean_squa  51/1500 [>.............................] - ETA: 2:11 - loss: 10.7802 - mean_square 111/1500 [=>............................] - ETA: 1:03 - loss: 9.2633 - mean_squared_error: 9.2633  57/1500 [>.............................] 132/1500 [=>............................] - ETA: 54s - loss: 8.5010 - mean_squared_error: 133/1500 [=>............................] - ETA: 54s - loss: 8.4891 - mean_squared_er  65/1500 [>.............................] - ETA: 1:49 - loss: 10.4380 131/1500 [=>............................] - ETA: 58s - loss: 9.3292 - mean_   6/1500 [..............................] - ETA: 21:17 - loss: 21.8265 - mean_squared_error: 21.8 - ETA: 1:31 - loss: 10.5814 - mean_squared_error: 10.5814  70/1500 [>.............................] - ETA: 1:53 - loss: 8.1524 - mean_squared_er  34/1500 [..............................] - ETA: 3:50 - loss: 9.8821 - mean_squared_error: 9.882 143/1500 [=>............................] - ETA: 56s - loss: 9.1761 - mean_squared_error: 9.1761  36/1500 [..............................] - ETA: 3:39 - loss: 9.8631 - mean_squared_error: 9.86  38/1500 [.............................. - ETA: 55s - loss: 9.1880 - mean_squared_error: 9.1880  14/1500 [..............................] - ETA: 9:32 - loss: 22.6215 - mean_squared_error: 22.62  77/1500 [>.............................] - ETA: 1:47 - loss: 8.4714 - mean_squared_error: 8.4714 147/1500 [=>............................] - ETA: 55s - loss: 9.1525 - mean_squared_error: 9.152 - ETA: 1:47 - loss: 8.3991 - mean_squared_error: 8.3991  16/1500 [........................... - ETA: 8:30 - loss: 22.4166 - mean_squared_error: 22.4 150/1500 [==>...........................] - ETA: 55s - loss: 9.1164 - mean_squared_error  20/1500 [..............................] - ETA: 6:55 - loss: 21.8241 - mean_squared_error: 21.82 - ETA: 1:25 - loss: 10.5837 - mean_square 100/1500 [=>............................] 170/1500 [==>...........................] - ETA: 51s - loss: 8.3014 - mean_squared_error: 8.3014 - ETA: 1:25 - loss: 10.8142 - mean_squared_error: 10.81 - ETA: 3:09 - loss: 9.7347 - mean_squared_error:    3/1500 [..............................] - ETA: 45:55 - loss: 9.7924 - mean_squared_error: 9.7924      46/1500 [..............................] - ETA: 3:07 - loss: 9.7452 - mean_squared_error - ETA: 27:46 - loss: 8.4758 - mean_squared_error: 8.  87/1500 [>.............................] - ETA: 1:42 - loss: 8.3552 - mean_squared_erro 106/1500 [=>............................] - ETA: 1:23 - loss: 11.0845 - mean_squared_error: 11.0845 175/1500 [==>...........................] - ETA: 51s - loss: 8.2644 - mean_squared_error: 8.  90/1500 [>.............................] 108/1500 [=>............................] - ETA: 1:40 - loss: 8.2990 - mean_squared_error: 8.299 - ETA: 1:22 - loss: 11.1316 - mean_squared_error:   11/1500 [............................. - ETA: 13:04 - loss: 6.2376 - mean_squared_error: 6.2376  92/1500 [>.............................] - ETA: 1:39 - loss: 8.3562 - mean_squared_error: 8.3562  37/1500 [..............................] - ETA: 4:02 - loss: 19.3449 - mean_squared_error: 19.344 179/1500 [==>...........................]  29/1500 [..............................] - ETA: 5:05 - loss: 7.2814 - mean_squared_error: 7.2814 - ETA: 51s - loss: 8.2148 - mean_s  16/1500 [............................. - ETA: 9:13 - loss: 6.3421 - mean_squared_error: 6  33/1500 [..............................] - ETA: 4:34 - loss: 7.0889 - mean_squared_error: 7.08  17/1500 [..............................] - ETA: 8:45 - loss: 6.4707 - mean_squared_error: 6 184/1500 [==>...........................] - ETA: 51s - loss: 8.1558 - mean_squared 118/1500 [=>............................] - ETA: 1:19 - loss: 11.1854 - mean_squared_error: 11.18  46/1500 [..............................] 176/1500 [==>...........................] - ETA: 3:24 - loss: 18.4235 - mean_squared_error: 18.4235 - ETA: 53s - loss: 8.9693 - mean_squared_error: 8.96 - ETA: 4:18 - loss: 7.1790 - mean_squared_error: 7 187/1500 [==>...........................] - ETA: 51s - loss: 8.0861 - mean_squared_error: 8 - ETA: 4:14 - loss: 7.1249 - mean_squared_error: 7.1249 104/1500 [=>............................] - ETA: 1:32 - loss: 8.4926 - mean_squared_error: 8.49  66/1500 [>.............................] - ETA: 2:24 - loss: 8.8892 - mean_squared_error: 189/1500 [==>...........................] - ETA: 51s - loss: 8.0864 - mean_squared_error: 8.0864 - ETA: 4:10 - loss: 7.3008 - mean_squared_error: 7 127/1500 [=>............................]  40/1500 [..............................] - ETA: 4:00 - loss: 7.2515 - mean_squared_error: 7.2515 - ETA: 1:15 - loss: 11.4260 - mean_squared_error - ETA: 2:13 - loss: 8.9009 - mean_squared_error  75/1500 [>.............................] - ETA: 2:11 - loss: 9.0327 - mean_squared_err  43/1500 [..............................] - ETA: 3:47 - loss: 7.2677 - mean_squared_error: 7. 197/1500 [==>...........................] - ETA: 50s - loss: 8.1155 - mean_squared_error: 8.11  44/1500 [..............................] - ETA: 3:44 - loss: 7.3528 - mean_squared_error: 7  37/1500 [..............................] - ETA: 4:22 - loss: 6.7593 - mean_squared_ 136/1500 [=>............................] - ETA: 1:14 - loss: 11.4068 - mean_squared_error: 11.4  41/1500 [............................. - ETA: 4:01 - loss: 7.1889 - mean_squared_er  44/1500 [..............................] - ETA: 3:47 - loss: 7.3171 - mean_squared_error: 7.3 204/1500 [===>..........................] - ETA: 51s - loss: 8.2426 - mean_squared_error: 8.2426  53/1500 [>.............................] - ETA: 3:14 - loss: 7.3463 - mean_squared 126/1500 [=>............................ - ETA: 1:23 - loss: 8.9114 - mean_squared_error: 8.9114  46/1500 [..............................] - ETA: 3:41 - loss: 7.2198 - mean_squared_error: 7 199/1500 [==>.......................... 208/1500 [===>..........................] - ETA: 50s - loss: 8.1651 - mean_squared_error: 8. - ETA: 1:51 - loss: 8.5215 - mean_squared_error: 8.5215 - ETA: 50s - loss: 8.1814 - mean_squared_error: 8  74/1500 [>.............................] - ETA: 2:23 - loss: 17.8685 - mean_squared_error: 17.  95/1500 [>.............................] - ETA: 1:51 - loss: 8.4875 - mean_squared_error:   75/1500 [>.............................] - ETA: 2:22 - loss: 17.8711 - mean_squared_er  99/1500 [>.............................] - ETA: 1:48 - loss: 8.5405 - mean_squared_error: 8 152/1500 [==>...........................] - ETA: 1:10 - loss: 11.6313 - mean_squared_error: 11 216/1500 [===>......................... - ETA: 50s - loss: 8.0971 - mean_squared_error: 8. 136/1500 [=>............................] - ETA: 1:20 - loss: 9.0904 - mean_squared_error:  83/1500 [>............................ - ETA: 2:12 - loss: 17.5910 - mean_squared_e 139/1500 [=>............................] - ETA: 1:19 - loss: 9.0430 - mean_squared_error: 9. 158/1500 [==>...........................] - ETA: 1:09 - loss: 11.6645 - mean_squared_error: 1 106/1500 [=>............................] - ETA: 1:44 - loss: 8.5588 - mean_squared_error - ETA: 51s - loss: 8.9714 - mean_squared_error: 8.9 107/1500 [=>............................] - ETA: 1:44 - loss: 8.  96/1500 [>.............................] - ETA: 1:59 - loss: 17.7199 - mean_squared_error: - ETA: 2:13 - loss: 7.1685 - mean_squared_err 100/1500 [=>........................... - ETA: 1:55 - loss: 17.6978 - mean_squared_error: 17.6  88/1500 [>.............................] - ETA: 2:11 - loss: 7.1050 - mean_squared_  69/1500 [>.............................] - ETA: 2:46 - loss: 7.1291 - mean_squared_error:   90/1500 [>............................. 154/1500 [==>...........................] - ETA: 2:09 - loss: 7.0685 - mean_squared_error: 7.0685 - ETA: 1:16 - loss: 8.9191 - mean_squared_error: 8.919\r",
      " - ETA: 1:13 - loss: 7.4311 - mean_squared_error: 7.4311 315/1500 [=====>........................] - ETA: 53s - loss: 11.5941 - mean_squared_error: 11.59418mean_squared_error: 11.7567 - ETA: 1:23 - loss: 16.9920 - mean_squared_error: 16.9920ror  72/1500 [>............................ - ETA: 2:42 - loss: 7.0554 - mean_ 108/1500 [=>............................] - ETA: 1:51 - loss: 17.8837 - mean_sq 185/1500 [==>...........................] - ETA: 1:04 - loss: 11.5371 - mean_squared_error: 11.  80/1500 [>............................ - ETA: 2:30 - loss: 7.0747 - mean_squared_error: 7.0747 240/1500 [===>..........................] - ETA: 50s - loss: 8.3880 - mean_squared_error: 8.388 111/1500 [=>............................] - ETA: 1:49 - loss: 17.8515 - mean_squared_error: 17. 165/1500 [==>...........................] - ETA: 1:14 - loss: 8.7804 - mean_squared_error: 8.78 127/1500 [=>............................] - ETA: 1:36 - loss: 8.7977 - mean_squared_error: 8.7977 113/1500 [=>........................... - ETA: 1:48 - loss: 17.8618 - mean_squared_error: 17.861 105/1500 [=>............................] 188/1500 [==>...........................] - ETA: 1:04 - loss: 11.4453 - mean_squared_error: 11.445 166/1500 [==>...........................] - ETA: 1:14 - loss: 8.7604 - mean_squared_error: 8.7 - ETA: 1:36 - loss: 8.7578 - mean_squared_error:  - ETA: 1:14 - loss: 8.8471 - mean_squared_error - ETA: 1:13 - loss: 8.8128 - mean_squared_error: 8.8 - ETA: 49s - loss: 8.3718 - mean_squared_error:  192/1500 [==>...........................] - ETA: 1:03 - loss: 11.4470 - mean_squared_er - ETA: 1:03 - loss: 11.5388 - mean_sq  94/1500 [>............................ - ETA: 2:14 - loss: 7.3673 - mean_squared_e 200/1500 [===>..........................] - ETA: 1:02 - loss: 11.5010 - mean_squared_error: 11.5010 140/1500 [=>............................] - ETA: 1:31 - loss: 9.0219 - mean_squared_error: 9.021 250/1500 [====>.........................] - ETA: 49s - loss: 8.7797 - mean_squared_err 182/1500 [==>...........................] - ETA: 1:11 - loss: 8.8005 - mean_squared_error: 8.80 - ETA: 50s - loss: 8.7552 - mean_squared_error: 8.7552 - ETA: 1:43 - loss: 17.3664 - mean_squared_error: 17.3 126/1500 [=>........................... - ETA: 1:42 - loss: 7.7986 - mean_squared_error: 7.7986 127/1500 [=>............................] - ETA: 1:43 - loss: 17.3585 - mean_squared_error: 1 128/1500 [=>............................] - ETA: 1:41 - loss: 7.7494 - mean_squared_e 101/1500 [=>............................] - ETA: 2:10 - loss: 7.4234 - mean_squared_error: 7.423 - ETA: 47s - loss: 8 274/1500 [====>.........................] 262/1500 [====>.........................] - ETA: 50s - loss: 8.8345 - mean_squared_error: 8.8345 - ETA: 48s - loss: 8.4356 - mean_squared_error: 8.43 - ETA: 1:37 - loss: 7.6690 - mean_squ 264/1500 [====>........................ 158/1500 [==>...........................] - ETA: 1:27 - loss: 9.2196 - mean_squared_error: 9.2196 276/1500 [====>.........................] - ETA: 48s - loss: 8.4385 - mean_squared_error: 8.4385 141/1500 [=>............................] - ETA: 1:38 - loss: 17.5647 - mean_squared_error: 17.5647 220/1500 [===>..........................] - ETA: 1:00 - loss: 11.5203 - mean_squared_error:  160/1500 [==>...........................] - ETA: 1:26 - loss: 9.2634 - mean_squared_err 195/1500 [==>...........................] - ETA: 1:11 - loss: 8.8517 - mean_squared_error: 8.8517 - ETA: 1:36 - loss: 7.5827 - mean_squared_error: 7.5827 - ETA: 1:37 - loss: 17.5057 - mean_squared_error: 17.5057 - ETA: 1:25 - loss: 9.2614 - mean_squared_error: 9. 163/1500 [==>.......................... - ETA: 1:25 - loss: 9.2218 - mean_squared_error: 9.2 - ETA: 1:37 - loss: 17.4760 - mean_squared_e - ETA: 1:37 - loss: 17.4023 - mean_squared 273/1500 [====>.........................] - ETA: 50s 156/1500 [==>...........................] - ETA: 1:32 - loss: 7.4675 - mean_s 159/1500 [==>...........................] - ETA: 1: 168/1500 [==>...........................] - ETA: 1:29 - loss: 17.1936 - mean_squared_err 219/1500 [===>.......................... - ETA: 1:08 - loss: 8.5908 - mean_squared_error: 8.5908 170/1500 [==>...........................] - ETA: 1:28 - loss: 17.1335 - mean_squared_error: 1 292/1500 [====>.........................] - ETA: 49s - loss: 8.6996 - mean_squared_error: 8.69 140/1500 [=>............................] - ETA: 1:27 - loss: 7.3320 - mean_squared_error: 7.3320 - ETA: 1:23 - loss: 9.2055 - mean_squa 310/1500 [=====>........................] - ETA: 47s - loss: 8.4066 - mean_squared_error: 8.4066 - ETA: 49s - ETA: 1:23 - loss: 17.0862 - mean_squared_error: 17. 267/1500 [====>.........................] - ETA: 56s - loss: 11.7113 - mean_squared_er - ETA: 46s - loss: 8.3968 - mean_squared_error - ETA: 46s - loss: 8.3902 - mean_squared_error: 8.3 270/1500 [====>.........................] - ETA: 55s - loss: 11.7845 - mean_squared_error:  188/1500 [==>...........................] - ETA: 1:23 - loss: 7.2664 - mean_squared_error: 7.26 - ETA: 49s - loss: 8.7899 - mean_squar 242/1500 [===>..........................] - ETA: 1:36 - loss: 7.5072 - mean_squared_error: 7.507 - ETA: 1:05 - loss: 8.6104 - mean_squared_erro 167/1500 [==>...........................] - ETA: 1:35 - loss: 7.5103 - mean_squared_error: 7.5103 278/1500 [====>.........................] - ETA: 55s - loss: 11.7083 - mean_squared_error: 11.708 245/1500 [===>..........................] - ETA: 1:04 - loss: 8.6199 - mean_squared_error: 8.6199 311/1500 [=====>........................] - ETA: 49s - loss: 8.7734 - mean_squar 248/1500 [===>..........................] 203/1500 [===>..........................] - ETA: 1:18 - loss: 7.4503 - mean_squared_error: 7.4 340/1500 [=====>........................] - ETA: 45s - loss: 8.3993 - mean_squared_error: 8.39 171/1500 [==>...........................] - ETA: 1:34 - loss: 7.4557 - mean_squared_error: 7.4 206/1500 [===>..........................] - ETA: 1:17 - loss: 7.3916 - mean_squared_error: 7.391 284/1500 [====>.........................] 342/1500 [=====>........................] - ETA: 54s - loss: 11.7483 - mean_squared_error: 11.7483 - ETA: 45s - loss: 8.3822 - mean_squared_error: 8. 318/1500 [=====>........................] - ETA: 48s - loss: 8.6925 - mean_squared_error: 8.6925 - ETA: 1:17 - loss: 9.1545 - mean_squared_error: 9. 285/1500 [====>.........................] - ETA: 54s - loss: 11.7239 - mean_squared_error: 11.72 210/1500 [===>..........................] - ETA: 1:16 - loss: 7.4081 - mean_squared_error: 7 - ETA: 48s - loss: 8.6584 - mean_squared_error: 8.6584 286/1500 [====>.........................] 175/1500 [==>........................... - ETA: 1:19 - loss: 17.0291 - mean_squared_error: 17.0291 - ETA: 1:33 - loss: 7.4486 - mean_squared_error: 7.4486 - ETA: 54s - loss: 11.7046 - mean_squared_error: 11.7046 345/1500 [=====>........................] - ETA: 45s - loss: 8.3623 - mean_squared_error: 8.3 257/1500 [====>.........................] 346/1500 [=====>........................] - ETA: 45s - loss: 8.3714 - mean_square 351/1500 [======>.......................] - ETA: 44s - loss: 8.4098 - mean_squared_error 262/1500 [====>......................... - ETA: 1:02 - loss: 8.6860 - mean_squ 185/1500 [==>...........................] - ETA: 1:30 - loss: 7.3686 - mean_squared_error: 7.368 297/1500 [====>........................ - ETA: 54s - loss: 11.6459 - mean_squared_error: 11 218/1500 [===>..........................] - ETA: 1:16 - loss: 7.4092 - mean_squared_error: 7.4 - ETA: 48s - loss: 8.6205 - mean_squ 190/1500 [==>............. 305/1500 [=====>........................] - ETA: 53s - loss: 11.5828 - mean_squared_error: 11.58 366/1500 [======>.......................] - ETA: 43s - loss: 8.4428 - mean_squared_erro 367/1500 [======>.......................] - ETA: 43s - loss: 8.4296 - mean_squared_er - ETA: 43s - loss: 8.4326 - me 371/1500 [======>.......................] - ETA: 43s - loss: 8.4466 - mean_squared_erro - ETA: 1:24 - loss: 7.4549 - mean_squared_error: 7 - ETA: 1:23 - loss: 7.5865 - mean_squared_ 245/1500 [===>..........................] - ETA: 1:11 - loss: 9.1649 - mean_squared_error: 9.1649 234/1500 [===>..........................]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 327/1500 [=====>........................] - ETA: 1:01 - loss: 16.9353 - mean_squared_error: 16.9353oss: 7.2305 - mean_squared_error: 7.2305 - ETA: 41s - loss: 8.5919 - mean_squared_error: 8.5919391s: 8.6080 - mean_squared_error: 8.6080.] 238/1500 [===>..........................] - ETA: 1:13 - loss: 17.0653 - mean_squared_error: 17.0653 379/1500 [======>.......................] - ETA: 43s - loss: 8.5266 - mean_squared_error: 8.526 - ETA: 59s - loss: 8.6743 - mean_squared_error: 8.6 357/1500 [======>.......................] - ETA: 46s - loss: 8.6588 - mean_squared_error: 8 214/1500 [===>..........................] - ETA: 1:21 - loss: 7.6435 - mean_squared_error: 7 239/1500 [===>..........................] 320/1500 [=====>........................] - ETA: 52s - loss: 11.5945 - mean_squared_error: 11.5945 249/1500 [===>..........................] - ETA: 1:10 - loss: 9.1308 - mean_squared_error: 9.1 215/1500 [===>..........................] 243/1500 [===>..........................] - ETA: 1:12 - loss: 17.0155 - mean_squared_error: 17.0 - ETA: 52s - loss: 11.6106 - mean_squared_error: 1 245/1500 [===>..........................] - ETA: 1:12 - loss: 17.0334 - mean_squared_error: 17.03 - ETA: 52s - loss: 11.6225 - mean_square 221/1500 [===>..........................] - ETA: 1:20 - loss: 7.6749 - mean_squared_error: 7.6749 - ETA: 1:11 - loss: 7.4996 - mean_squared_error: 7.49 - ETA: 1:11 - loss: 7.6030 - mean_squared_error: 7.60 251/1500 [====>.........................] - ETA: 1:11 - loss: 17.0101 - mean_squared_error: 17 - ETA: 1:10 - loss: 7.6029 - mean_squared_error: 7.6029 258/1500 [====>.........................] - ETA: 1:09 - loss: 9.0962 - mean_squared_error: 9.09 372/1500 [======>.......................] - ETA: 45s - loss: 8.6728 - mean_squared_error: 8.6 253/1500 [====>.........................] - ETA: 1:10 - loss: 7.5740 - mean_squared_error: 258/1500 [====>.........................] - ETA: 1:09 - loss: 17.0787 - mean_squared_error: 17.0787 310/1500 [=====>........................] - ETA: 56s - loss: 8.7762 - mean_squared_error: 8.7 263/1500 [====>........................ - ETA: 1:08 - loss: 9.1062 - mean_squared_error: 9.1 - ETA: 56s - loss: 8.7684 - mean_squared_error: - ETA: 1:09 - loss: 17.0988 - mean_squared_error: 17.0988 - ETA: 1:09 - loss: 7.5246 - mean_squared_error: 7.5246 - ETA: 56s - loss: 8.7400 - mean_squared_error: 8. 233/1500 [===>......................... - ETA: 1:17 - loss: 7.6924 - mean_squar 317/1500 [=====>........................] - ETA: 56s - loss: 8.7170 - mean_squared_error: 8. 270/1500 [====>.........................] - ETA: 1:07 - loss: 9.1498 - mean_squared_error: 9 385/1500 [======>................... 321/1500 [=====>........................] - ETA: 55s - loss: 8.6865 - mean_squared_error: 8.686 346/1500 [=====>........................] - ETA: 50s - loss: 11.6034 - mean_squared_error: 1 - ETA: 1:06 - loss: 9.1085 - mean_squared_error: 9.1085 405/1500 [=======>......................] - ETA: 42s - loss: 8.4481 - mean_squared_error: 8.4481 348/1500 [=====>........................] - ETA: 50s - loss: 11.5877 - mean_squared_error: 11.5877 323/1500 [=====>........................] - ETA: 55s - loss: 8.6762 - mean_squared_error:  391/1500 [======>.......................] - ETA: 44s - loss: 8.6538 - mean_squared_error: 8.653 406/1500 [=======>......................] - ETA: 42s - loss: 8.4379 - mean_squared_error: 8.43 268/1500 [====>.........................] - ETA: 1:08 - loss: 7.4792 - mean_squared_error: 7.4 247/1500 [===>..........................] - ETA: 1:14 - loss: 7.6216 - mean_squared_error: 7 269/1500 [====>........................ - ETA: 1:08 - loss: 7.4632 - mean_squared_e 250/1500 [====>.........................] - ETA: 1:14 - loss: 7.6521 - mean_squared_error: 399/1500 [======>.......................] - ETA: 43s - loss: 8.6442 - mean_squared_error: 8.6 252/1500 [====>.........................] - ETA: 1:13 - loss: 7.6196 - mean_squared_error: 7.61 400/1500 [=======>......................] - ETA: 43s - loss: 8.6534 - mean_squared_error: 8.653 415/1500 [=======>......................] - ETA: 42s - loss: 8.5055 - mean_squared_error: 8 277/1500 [====>.........................] - ETA: 1:07 - loss: 7.4142 - mean_squared_error: 281/1500 [====>.........................] - ETA: 1:06 - loss: 17.0490 - mean_squared_error: 17 289/1500 [====>.........................] - ETA: 1:04 - loss: 9.0249 - mean_squared_error - ETA: 41s - loss: 8.4732 - mean_squared_error: 8.47 282/1500 [====>.........................] - ETA: 1:06 - loss: 7.3825 - mean_squared_error: 7.382 283/1500 [====>.........................] - ETA: 1:06 - loss: 7.3830 - mean_squared_error: 7.3830 - ETA: 53s - loss: 8.7317 - mean_squared_error: 8.731 293/1500 [====>.........................] - ETA: 1:04 - loss: 9.1663 - mean_squared_error: 9.16 260/1500 [====>.........................] - ETA: 1:12 - loss: 7.5144 - mean_squared_error: 262/1500 [====>.........................] - ETA: 1:12 - loss: 7.4925 - mean_squared_error: 264/1500 [====>.........................] - ETA: 1:12 - loss: 7.4576 - mean_squared_error: 7.45 371/1500 [======>.......................] - ETA: 48s - loss: 11.6150 - mean_squared_error: 11 - ETA: 1:03 - loss: 9.1073 - mean_squared_e 420/1500 [=======>......................] - ETA: 42s - loss: 8.6287 - mean_squared_error: 8.6 270/1500 [====>.........................] - ETA: 1:10 - loss: 7.4935 - mean_squared_error: 7.49 295/1500 [====>.........................] - ETA: 1:04 - loss: 7.3355 - mean_squared_error: 7. 272/1500 [====>.........................] - ETA: 1:10 - loss: 7.5459 - mean_squared_error: 7. 306/1500 [=====>........................] - ETA: 1:02 - loss: 9.1243 - mean_squared_err 298/1500 [====>........................ - ETA: 1:04 - loss: 7.3203 - mean_squared_err 440/1500 [=======>......................] 383/1500 [======>.......................] - ETA: 47s - loss: 11.5810 - mean_squared_error: 11.5810 - ETA: 40s - loss: 8.4007 - mean_squared_error: 8.40 - ETA: 1:02 - loss: 9.1523 - mean_squared_error:  360/1500 [======>.......................] - ETA: 47s - loss: 11.5759 - mean_squared_error: 11 305/1500 [=====>........................] - ETA: 1:03 - loss: 16.8974 - mean_squared_error: 16. 282/1500 [====>.........................] - ETA: 1:08 - loss: 7.6737 - mean_squared_error: 7.6737 443/1500 [=======>......................] - ETA: 40s - loss: 8.4808 - mean_squared_error: 8.4808 - ETA: 47s - loss: 11.5734 - mean_squared_error: 11.573 308/1500 [=====>........................] - ETA: 1:03 - loss: 16.8597 - mean_squared_error: 16.8 363/1500 [======>.......................] - ETA: 52s - loss: 8.8838 - mean_squared_error: 8 310/1500 [=====>........................] - ETA: 1:02 - loss: 7.2858 - mean_squared_error: 7.28 436/1500 [=======>......................] - ETA: 41s - loss: 8.5979 - mean_squared_error: 8.59 389/1500 [======>.......................] - ETA: 47s - loss: 11.5826 - mean_squared_erro 448/1500 [=======>......................] - ETA: 40s - loss: 8.4511 - mean_squared_error: 8.4 368/1500 [======>.......................] - ETA: 51s - loss: 8.8420 - mean_squared_error - ETA: 1:07 - loss: 7.6407 - mean_squared_error: 7.64 323/1500 [=====>........................ 317/1500 [=====>........................] 452/1500 [========>.....................] - ETA: 40s - loss: 8.4503 - mean_squared_error: 8.45 292/1500 [====>.........................] - ETA: 1:07 - loss: 7.6228 - mean_squared_error: 7.62 441/1500 [=======>......................] - ETA: 41s - loss: 8.5839 - mean_squared_error: 8.58 400/1500 [=======>......................] - ETA: 46s - loss: 11.5502 - mean_squared_ 456/1500 [========>.....................] - ETA: 40s - loss: 8.4321 - mean_squared_error: 8.43 322/1500 [=====>........................] - ETA: 1:01 - loss: 17.0076 - mean_squared_error: 17.0076 325/1500 [=====>........................] - ETA: 1:00 - loss: 7.2586 - mean_squared_error: 7.2586 - ETA: 1:00 - loss: 9.0799 - mean_squared_error: 9.0799 - ETA: 40s - loss: 8.4395 - mean_squared_error:  330/1500 [=====>............... - ETA: 1:06 - loss: 7.6500 - mean_squared_error: 7 301/1500 [=====>........................] - ETA: 1:06 - loss: 7.6393 - mean_squared_error: 7.6393"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 382/1500 [======>.......................] - ETA: 56s - loss: 16.9182 - mean_squared_error: 16.9182oss: 17.0273 - mean_squared_error: 17.0273 427/1500 [=======>......................]rror: 11.593 - ETA: 56s - loss: 8.9280 - mean_squared_error: 8.9280: 7.2379 - mean_squared_error: 7. 335/1500 [=====>........................] - ETA: 1:00 - loss: 9.1346 - mean_squared_error: 9.13 455/1500 [========>.....................] - ETA: 40s - loss: 8.5314 - mean_squared_error: 333/1500 [=====>........................ - ETA: 1:00 - loss: 17.0727 - mean_squared_error: 334/1500 [=====>........................] - ETA: 1:00 - loss: 17.0882 - mean_squared_error: 17.0 389/1500 [======>....................... 336/1500 [=====>........................] - ETA: 50s - loss: 8.8426 - mean_squared_error: 8.8426 - ETA: 1:00 - loss: 17.1396 - mean_squared_error: 17.13 344/1500 [=====>........................ 338/1500 [=====>........................] - ETA: 1:00 - loss: 17.1240 - mean_squared_error: 17 476/1500 [========>.................... 316/1500 [=====>........................] - ETA: 1:04 - loss: 7.5402 - mean_squared_error: 7.5 348/1500 [=====>........................] - ETA: 58s - loss: 9.0051 - mean_square 351/1500 [======>.......................] - ETA: 58s - loss: 8.9922 - mean_squared_error: 8. - ETA: 40s - loss: 8.5173 - mean_squared_error 432/1500 [=======>......................] - ETA: 44s - loss: 11.6210 - mean_squared_error: 11.6210 484/1500 [========>.....................] 354/1500 [======>.......................] - ETA: 39s - loss: 8.3902 - mean_squared_error: 8.3902 - ETA: 57s - loss: 7.2382 - mean_squared_error: 7. 349/1500 [=====>........................ - ETA: 58s - loss: 17.0333 - mean_squared_error: 17.033 486/1500 [========>.....................] - ETA: 38s - loss: 8.4130 - mean_squared_error: 8.4 - ETA: 40s - loss: 8.5650 - mean_squared_error: 8. 438/1500 [=======>......................] - ETA: 44s - loss: 11.5972 - mean_squared_error: 11.5972 472/1500 [========>.....................] - ETA: 40s - loss: 8.5819 - mean_squ 361/1500 [======>.......................] - ETA: 57s - loss: 8.9206 - mean_squared_error 413/1500 [=======>......................] 357/1500 [======>.......................] - ETA: 48s - loss: 8.9300 - mean_squared_error: 8.9300 367/1500 [======>.......................] 336/1500 [=====>........................] - ETA: 55s - loss: 7.2678 - mean_squared_error: 7.2678 - ETA: 1:02 - loss: 7.4403 - mean_squared_error: 7.4 366/1500 [======>.......................] - ETA: 56s - loss: 8.9285 - mean_squared_error: 8.9285 496/1500 [========>.....................] - ETA: 38s - loss: 8.3748 - mean_squared_error: 8.3 368/1500 [======>.......................] - ETA: 55s - loss: 7.2574 - mean_squared_error: 7.25 417/1500 [=======>......................] - ETA: 48s - loss: 8.9979 - mean_squared_error: 8.99 448/1500 [=======>......................] 369/1500 [======>.......................] - ETA: 56s - loss: 8.9081 - mean_squared_error: 8.9081 498/1500 [========>.....................] - ETA: 38s - loss: 8.3580 - mean_squared_error: 8.3580 - ETA: 40s - loss: 8.5301 - mean_squared_error: 8.5 340/1500 [=====>........................] - ETA: 1:01 - loss: 7.4152 - mean_squared_error: 7. 373/1500 [======>.......................] - ETA: 55s - loss: 7.2843 - mean_squared_error: 7.28 363/1500 [======>.......................] - ETA: 57s - loss: 17.0145 - mean_squared_error: 17.01 374/1500 [======>.......................] - ETA: 55s - loss: 7.2752 - mean_squared_error: 7.2752 372/1500 [======>.......................] - ETA: 56s - loss: 8.9225 - mean_squared_error: 8. 342/1500 [=====>........................ - ETA: 1:01 - loss: 7.4153 - mean_squared_error: 7.4153 423/1500 [=======>......................] - ETA: 48s - loss: 9.0002 - mean_squared_error:  368/1500 [======>.......................] - ETA: 57s - loss: 17.0570 - mean_squared_error: 17.0 488/1500 [========>.....................] - ETA: 39s - loss: 8.5937 - mean_squared_error: 8. - ETA: 47s - loss: 8.9914 - mean_squared_error: 8.9914 - ETA: 55s - loss: 8.9560 - mean_squared_error: 8. 508/1500 [=========>....................] - ETA: 38s - loss: 8.3582 - mean_squared_error: 8.3582 381/1500 [======>.......................] - ETA: 54s - loss: 7.2707 - mean_squared_error: 7.270 - ETA: 47s - loss: 8.9895 - mean_squared_error: 8.98 458/1500 [========>..................... 491/1500 [========>.....................] 509/1500 [=========>....................] - ETA: 38s - loss: 8.3478 - mean_squared_error: 459/1500 [========>.....................] - ETA: 43s - loss: 11.6178 - mean_squared_error: 11.617 433/1500 [=======>......................] - ETA: 47s - loss: 9.0041 - mean_square 436/1500 [=======>......................] - ETA: 47s - loss: 8.9666 - mean_squared_error: 8.9666 391/1500 [======>.......................] - ETA: 53s - loss: 7.2033 - mean_squared_error: 7. - ETA: 43s - loss: 11.6013 - mean_squared_error: 389/1500 [======>.......................] - ETA: 54s - loss: 8.9340 - mean_squared_"
     ]
    }
   ],
   "source": [
    "nbloop =5\n",
    "NbIndividual =3\n",
    "nbChildAllowed = 4\n",
    "\n",
    "pkgNameOriginal = params.LEARNINGBASE_ORIGIN\n",
    "pkgNameBut = params.LEARNINGBASE_BUT\n",
    "InitialNbIndividual =3\n",
    "naturalSelectionPercentage = 0.5\n",
    "\n",
    "a = ReinforceOptimalityWithGenetic(Train_GEN, Val_GEN, pkgNameOriginal, pkgNameBut,\\\n",
    "                    InitialNbIndividual, Idealpopulation,nbChildAllowed, nbloop, Y_Vol, \"Vol\",params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
